---
layout: home
title: Reinforcement learning
author_profile: true

header:
      image: /assets/images/rsz_go_game_crop.jpg
      #image: /assets/images/robot_board_light_crop.jpg
      #overlay_image: /assets/images/foggy.jpg
      #overlay_filter: 0.1
---

# Reinforcement learning

This repository contains codes that I have reproduced for various RL algorithms. The codes were tested on Colab.

## Implemented Algorithms

| **Algorithms**              | **Discrete**                      | **Continuous**                    | Multithreaded                     | Multiprocessing                  | **Tested on**            |
| --------------------------- | --------------------------------- | --------------------------------- |-----------------------------------|----------------------------------|--------------------------|
| DQN                         | :heavy_check_mark:                |                                   |                                   |                                  | CartPole-v0              |
| Double DQN (DDQN)           | :heavy_check_mark:                |                                   |                                   |                                  | CartPole-v0              |
| Dueling DDQN                | :heavy_check_mark:                |                                   |                                   |                                  | CartPole-v0              |
| Dueling DDQN + PER          | :heavy_check_mark:                |                                   |                                   |                                  | CartPole-v0              |
| A3C <sup>(1)</sup>          | :heavy_check_mark:                | :heavy_check_mark:                | :heavy_check_mark:                | :heavy_check_mark:               | CartPole-v0, Pendulum-v0 |
| DPPO <sup>(2)</sup>         |                                   | :heavy_check_mark:                |                                   | :heavy_check_mark:<sup>(3)</sup> | Pendulum-v0              |
| RDN + PPO                   |                                   | :heavy_check_mark:                |                                   |                                  | MountainCarContinuous-v0 |

<sup><sup>(1): N-step returns used for critic's target.</sup></sup><br>
<sup><sup>(1): GAE used for computation of TD lambda return (for critic's target) & policy's advantage.</sup></sup><br>
<sup><sup>(3): Distributed Tensorflow & Python's multiprocessing package used.</sup></sup><br>

<br>
"Do not worry about your difficulties in Mathematics.
<br>
 I can assure you mine are still greater."
 <br>
 - Einstein

<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Home</title>
  </head>
  <body>
    <h1>
    </h1>
    <p>
    </p>
  </body>
</html>
