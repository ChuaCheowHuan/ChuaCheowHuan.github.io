<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Duel_ddqn</title>
    <link rel="stylesheet" href="/assets/css/styles.css">

    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async>
    </script>

  </head>
  <body>
    <nav>
  
    <a href="/" >Home</a>
  
    <a href="/about.html" >About</a>
  
    <a href="/blog.html" >Blog</a>
  
</nav>

    <!--
<h1>DUEL_DDQN</h1>
-->
<p>
  10 Mar 2019
  
  
    <!--
      - <a href="/authors/ChuaCheowHuan.html">Chua Cheow Huan</a>
      -->
  
</p>

<p>Dueling DDQN</p>

<p>A <strong>Dueling Double DQN (Dueling DDQN)</strong> implementation in tensorflow with random experience replay.</p>

<p>Environment from openai gym: CartPole-v0</p>

<hr />
<p><br />
<strong>Notations</strong></p>

<p>Network = <script type="math/tex">Q_{\theta}</script> <br />
Parameter = <script type="math/tex">\theta</script> <br />
Network Q value = <script type="math/tex">Q_{\theta}</script> (s, a) <br />
<br />
Value function = V(s) <br />
Advantage function = A(s, a) <br />
<br />
Parameter from the Advantage function layer = <script type="math/tex">\alpha</script> <br />
Parameter from the Value function layer = <script type="math/tex">\beta</script></p>

<hr />
<p><br />
<strong>Equations</strong></p>

<p>(eqn 9) from the original paper <a href="https://arxiv.org/pdf/1511.06581.pdf">(Wang et al., 2015)</a>: <br />
Q(s, a; <script type="math/tex">\theta</script>, <script type="math/tex">\alpha</script>, <script type="math/tex">\beta</script>) =
V(s; <script type="math/tex">\theta</script>, <script type="math/tex">\beta</script>)
<script type="math/tex">+</script> <br />
<script type="math/tex">\hspace{50pt}</script>
[ A(s, a; <script type="math/tex">\theta</script>, <script type="math/tex">\alpha</script>)
<script type="math/tex">-</script>
<script type="math/tex">\frac{1}{|A|}</script> <script type="math/tex">\sum_{a'}</script> A(s, <script type="math/tex">a^{'}</script>; <script type="math/tex">\theta</script>, <script type="math/tex">\alpha</script>) ]</p>

<hr />
<p><br />
<strong>Implementation details</strong></p>

<p>V represents the value function layer, A represents the Advantage function layer:</p>
<blockquote>
  <p><img src="https://drive.google.com/uc?export=view&amp;id=1f901lKe-Fa_Y4ITX8NFNeMO7IX_O2fB9" alt="alt text" /></p>
</blockquote>

<hr />
<p><br />
<strong>References</strong></p>

<p><a href="https://arxiv.org/pdf/1511.06581.pdf">Dueling Network Architectures for Deep Reinforcement Learning
(Wang et al., 2015)</a></p>


  </body>
</html>
