<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.15.2 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">



<link rel="stylesheet" href="/assets/css/main.css">
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async>
</script>



  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Custom MARL (multi-agent reinforcement learning) CDA (continuous double auction) environment - Every little gist</title>
<meta name="description" content="A custom MARL (multi-agent reinforcement learning) environment where multipleagents trade against one another in a CDA (continuous double auction).">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Every little gist">
<meta property="og:title" content="Custom MARL (multi-agent reinforcement learning) CDA (continuous double auction) environment">
<meta property="og:url" content="https://chuacheowhuan.github.io/MARL_CDA_env/">


  <meta property="og:description" content="A custom MARL (multi-agent reinforcement learning) environment where multipleagents trade against one another in a CDA (continuous double auction).">



  <meta property="og:image" content="https://chuacheowhuan.github.io/assets/images/bio-photo.jpg">





  <meta property="article:published_time" content="2019-08-11T00:00:00+08:00">





  

  


<link rel="canonical" href="https://chuacheowhuan.github.io/MARL_CDA_env/">





  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Organization",
      "url": "https://chuacheowhuan.github.io",
      "logo": "https://chuacheowhuan.github.io/assets/images/bio-photo.jpg"
    }
  </script>



  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "Chua Cheow Huan",
      "url": "https://chuacheowhuan.github.io",
      "sameAs": null
    }
  </script>



  <meta name="google-site-verification" content="googlec75336ce8806a8d5.html" />





<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Every little gist Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--posts">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">Every little gist</a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/" >Home</a>
            </li><li class="masthead__menu-item">
              <a href="/blog/index.html" >Blog</a>
            </li><li class="masthead__menu-item">
              <a href="/about/index.html" >About</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name"></h3>
    
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>

  <div class="archive">
    
      <h1 id="page-title" class="page__title">Custom MARL (multi-agent reinforcement learning) CDA (continuous double auction) environment</h1>
    
    <p>A custom MARL (multi-agent reinforcement learning) environment where multiple
agents trade against one another in a CDA (continuous double auction).</p>

<p>The environment doesn’t use any external data. Data is generated by self play
of the agents themselves through their interaction with the limit order book.</p>

<p>At each time step, the environment emits the top k rows of the aggregated
order book as observations to the agents. Each agent then samples an action from
the action space &amp; all actions are randomly shuffled before execution in each
time step.</p>

<p>Each time step is a snapshot of the limit order book &amp; a key assumption is that
all traders(agents) suffer the same lag (wait for all traders to have their
orders executed before seeing the next LOB snapshot).</p>

<hr />

<p>This is <strong>WIP</strong>.</p>

<p>Code on my <a href="https://github.com/ChuaCheowHuan/gym-continuousDoubleAuction">Github</a></p>

<hr />

<h1 id="contents">Contents:</h1>
<p>1) <a href="#update">Update</a></p>

<p>2) <a href="#purpose-of-this-repository">Purpose of this repository</a></p>

<p>3) <a href="#example">Example</a></p>

<p>4) <a href="#dependencies">Dependencies</a></p>

<p>5) <a href="#installation">Installation</a></p>

<p>6) <a href="#todo">TODO</a></p>

<p>7) <a href="#acknowledgements">Acknowledgements</a></p>

<p>8) <a href="#contributing">Contributing</a></p>

<p>9) <a href="#disclaimer">Disclaimer</a></p>

<p>10) <a href="#making-sense-of-the-render-output">Making sense of the render output</a></p>

<hr />

<h1 id="update">Update:</h1>
<p>20200304</p>

<p>1) Upgraded to use (for training script):</p>

<p>tensorflow 2.10</p>

<p>ray[RLlib] 0.8.2</p>

<p>2) New “mixed” (discrete and continuous) action space. (This action space could
be changed in the future to make way for action spaces that make more sense.)</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>act_space = spaces.Tuple((spaces.Discrete(3), # side: none, bid, ask (0 to 2)
                          spaces.Discrete(4), # type: market, limit, modify, cancel (0 to 3)

                          # for size selection:
                          spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32), # array of mean
                          spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=np.float32), # array of sigma

                          spaces.Discrete(12), # price: based on mkt depth from 0 to 11
                        ))
</code></pre></div></div>

<p>Example model output:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0, 3, array([0.47555637], dtype=float32), array([0.5383144], dtype=float32), 5]
</code></pre></div></div>

<p>3) Tweak code to allow bid ask spread to narrow more efficiently during
simulation.</p>

<p>4) Improved render standard <a href="#making-sense-of-the-render-output">output</a>.</p>

<p>5) Includes new Jupyter notebook training script (implemented with RLlib),
tested in Colab.</p>

<hr />

<h1 id="purpose-of-this-repository">Purpose of this repository:</h1>
<p>The purpose of this repository is to create a custom MARL (multi-agent reinforcement learning) environment where multiple
agents trade against one another in a CDA (continuous double auction).</p>

<p>The environment doesn’t use any external data. Data is generated by self play
of the agents themselves through their interaction with the limit order book.</p>

<p>At each time step, the environment emits the top k rows of the aggregated
order book as observations to the agents.</p>

<p>observation_space:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>inf = float('inf')
neg_inf = float('-inf')
obs_row = 4
obs_col = 10
self.observation_space = spaces.Box(low=neg_inf, high=inf, shape=(obs_row, obs_col))
</code></pre></div></div>

<h1 id="example">Example:</h1>
<p>An example of using RLlib to pit 1 PPO (Proximal Policy Optimization) agent
against 3 random agents using this CDA environment is available in:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CDA_env_disc_RLlib.py
</code></pre></div></div>

<p>To <strong>run</strong> the environment with the sample training script:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd gym-continuousDoubleAuction/gym_continuousDoubleAuction

$ python CDA_env_disc_RLlib.py
</code></pre></div></div>

<hr />

<p><strong>Alternative ways</strong> to run this environment:</p>

<p>1) By using the Jupyter notebook <code class="highlighter-rouge">CDA_env_disc_RLlib.ipynb</code>.
This notebook contains a sample training script (implemented with Ray RLlib)
&amp; is tested in Colab.</p>

<p>2) By using the python <code class="highlighter-rouge">CDA_env_rand.py</code> script which is basically running a CDA
simulator with dummy (non-learning) random agents.</p>

<hr />

<p>Running the following tensorboard command &amp; navigate to <code class="highlighter-rouge">localhost:6006</code> in
your browser to access the <strong>tensorboard graphs</strong>:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ tensorboard --logdir ~/ray_results
</code></pre></div></div>

<hr />

<p>The figure below from Tensorboard shows the agents’ performance:</p>

<p><img src="/assets/images/MARL_CDA_env/agent0and1.png" alt="image" />
<img src="/assets/images/MARL_CDA_env/agent2and3.png" alt="image" /></p>

<p>PPO agent is using policy 0 while policies 1 to 3 are used by the random agents.</p>

<hr />

<h1 id="dependencies">Dependencies:</h1>

<p>1) tensorFlow</p>

<p>2) ray[rllib]</p>

<p>3) pandas</p>

<p>4) sortedcontainers</p>

<p>5) sklearn</p>

<p>For a full list of dependencies &amp; versions, see <code class="highlighter-rouge">requirements.txt</code> in this
repository.</p>

<h1 id="installation">Installation:</h1>
<p>The environment is installable via pip.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd gym-continuousDoubleAuction

$ pip install -e .
</code></pre></div></div>

<h1 id="todo">TODO:</h1>
<p>1) Custom RLlib workflow to include custom RND + PPO policies.
(for training script).
2) Parametric or hybrid action space (or experiment with different types of
  action space).
3) More robust tests (add LOB test into test script).
4) Better documentation.
5) Logging of trading data for all steps (for visualization after simulation).
6) Move action consequences after each step by each agent into the respective
info dictionary.
7) A random starting price for better narrowing of spread (currently need many iterations for spread to narrow).
8) Instead of traders(agents) having the same lag, introduce zero lag
(Each LOB snapshot in each t-step is visible to all traders) or random lag.
9) Allow traders to have different starting capital.</p>

<h1 id="acknowledgements">Acknowledgements:</h1>
<p>The orderbook matching engine is adapted from
https://github.com/dyn4mik3/OrderBook</p>

<h1 id="contributing">Contributing:</h1>
<p>Please see <a href="https://github.com/ChuaCheowHuan/gym-continuousDoubleAuction/blob/master/CONTRIBUTING.md">CONTRIBUTING.md</a>.</p>

<h1 id="disclaimer">Disclaimer:</h1>
<p>This repository is only meant for research purposes &amp; is <strong>never</strong> meant to be
used in any form of trading. Past performance is no guarantee of future results.
If you suffer losses from using this repository, you are the sole person
responsible for the losses. The author will <strong>NOT</strong> be held responsible in any
way.</p>

<hr />

<h1 id="making-sense-of-the-render-output">Making sense of the render output:</h1>

<p><strong>The step separator:</strong></p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>************************************************** t_step = 306 **************************************************
</code></pre></div></div>
<hr />

<p><strong>Actions:</strong></p>

<p>Actions output from the model:</p>

<p>1) Each column represents the action from each trader(agent).</p>

<p>2) Row 1 represents the side: none, bid, ask (0 to 2).</p>

<p>3) Row 2 represents the type: market, limit, modify, cancel.</p>

<p>4) Row 3 represents the mean for size selection.</p>

<p>5) Row 4 represents the sigma for size selection.</p>

<p>6) Row 5 represents the price: based on LOB market depth from 0 to 11.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model actions:
 --  --  --  --
 1   1   1   2
 1   0   0   1
39  29   6  17
19  89  13   0
 7   4   9  10
--  --  --  --
</code></pre></div></div>

<p>1) Column 1 represents the ID of each trader(agent).</p>

<p>2) Column 2 the side: none, bid, ask (0 to 2).</p>

<p>3) Column 3 type: market, limit, modify, cancel.</p>

<p>4) Column 4 represents the order size.</p>

<p>5) Column 5 represents the order price.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Formatted actions acceptable by LOB:
 -  ---  ------  -----  --
0  bid  limit   38982  15
1  bid  market   5779   0
2  bid  market    999   0
3  ask  limit   17001  47
-  ---  ------  -----  --
Shuffled action queue sequence for LOB executions:
 -  ---  ------  -----  --
3  ask  limit   17001  47
2  bid  market    999   0
1  bid  market   5779   0
0  bid  limit   38982  15
-  ---  ------  -----  --
</code></pre></div></div>

<hr />

<p><strong>Rewards, dones, &amp; infos:</strong></p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rewards:
 {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0}

dones:
 {'__all__': True}

infos:
 {0: {}, 1: {}, 2: {}, 3: {}}
</code></pre></div></div>

<hr />

<p><strong>Aggregated LOB:</strong></p>

<p>1) The columns represents the 10 levels (1 to 10, left to right) of the market
depth in the LOB.</p>

<p>2) Row 1 represents the bid size.</p>

<p>3) Row 2 represents the bid price.</p>

<p>4) Row 3 represents the ask size.</p>

<p>5) Row 4 represents the ask price.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>agg LOB @ t-1
 ------  -----  ------  ------  ------  ------  ------  ------  ------  ------
  7746  19011  126634  116130   43073  124055   74977  188096  139117  143968
    23     22      21      20      19      15      14      12      11      10
-62448  -7224  -65989  -96940  -77985  -93987  -55942   -4173  -16998  -81011
   -36    -37     -38     -39     -40     -41     -42     -43     -47     -48
------  -----  ------  ------  ------  ------  ------  ------  ------  ------
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>agg LOB @ t
 ------  -----  ------  ------  ------  ------  ------  ------  ------  ------
  7746  19011  126634  116130   43073  163037   74977  188096  139117  143968
    23     22      21      20      19      15      14      12      11      10
-56669  -7224  -65989  -96940  -77985  -93987  -55942   -4173  -33999  -81011
   -36    -37     -38     -39     -40     -41     -42     -43     -47     -48
------  -----  ------  ------  ------  ------  ------  ------  ------  ------
</code></pre></div></div>

<hr />

<p><strong>LOB bids:</strong></p>

<p>The current limit bid orders in the LOB.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LOB:
 ***Bids***
     size price  trade_id  timestamp  order_id
0    7746    23         0        345       265
1   19011    22         1        344       231
2   14553    21         2        107        99
3   63025    21         1        333       209
4   49056    21         3        349       268
5   89029    20         2         53        53
6   24060    20         0        201        46
7    3041    20         1        297       229
8   43073    19         1         35        35
9   42989    15         1        340       234
10  81066    15         3        336       259
11  38982    15         0        359       275
12  63003    14         0        253       201
13  11974    14         1        285       168
14  18089    12         3        351       105
15  91998    12         0        343       264
16  78009    12         1        352        40
17  45039    11         3        123       101
18  94078    11         0        204       172
19  97967    10         3        223       185
20  46001    10         1        313       243
21  45871     9         2         52        52
22  94993     9         3        209       176
</code></pre></div></div>

<hr />

<p><strong>LOB asks:</strong></p>

<p>The current limit ask orders in the LOB.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>***Asks***
     size price  trade_id  timestamp  order_id
0   40654    36         3        322       250
1   16015    36         0        323       251
2    7224    37         1        272       214
3   39980    38         3        299       190
4   26009    38         1        261       206
5   58977    39         0        231       188
6   37963    39         3        284       164
7   15995    40         0        305       235
8   61990    40         3        328       254
9   93987    41         0        353       143
10  55942    42         1        290       189
11   4173    43         0        112       104
12  16998    47         1        341       239
</code></pre></div></div>

<hr />

<p><strong>Tape (Time &amp; sales):</strong></p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>***tape***
    size price  timestamp  counter_party_ID  init_party_ID init_party_side
0   5779    36        358                 3              1             bid
1   5894    36        356                 3              0             bid
2  13347    36        355                 3              1             bid
3   2272    36        354                 3              0             bid
4    894    23        350                 0              1             ask
5  12874    23        347                 0              0             ask
6   7501    23        346                 0              1             ask
7   9405    22        342                 1              3             ask
</code></pre></div></div>

<hr />

<p><strong>Trades:</strong></p>

<p>Trades that took place when executing the action of a trader(agent) at t-step.</p>

<p>act_seq_num represents the sequence of the action. In this case, it’s the
2nd action executed at t-step.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TRADES (act_seq_num): 2
   seq_Trade_ID  timestamp price    size  time  counter_ID counter_side  counter_order_ID counter_new_book_size  init_ID init_side init_order_ID init_new_LOB_size
0             0        358    36  5779.0   358           3          ask               250                 40654        1       bid          None              None
</code></pre></div></div>

<hr />

<p><strong>New order in LOB:</strong></p>

<p>The new limit orders inserted into LOB
(includes unfilled leftover quantity from previous order).</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>order_in_book (act_seq_num): 0
type    side      quantity    price    trade_id    timestamp    order_id
------  ------  ----------  -------  ----------  -----------  ----------
limit   ask          17001       47           3          357         273
order_in_book (act_seq_num): 3
type    side      quantity    price    trade_id    timestamp    order_id
------  ------  ----------  -------  ----------  -----------  ----------
limit   bid          38982       15           0          359         275
</code></pre></div></div>

<hr />

<p><strong>Mark to market profit @ t-step:</strong></p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mark_to_mkt profit@t:
ID: 0; profit: 1491150.999999999999999999998
ID: 1; profit: 3583508.999999999999999999995
ID: 2; profit: -7421583.999999999999999999999
ID: 3; profit: -676658.0000000000000000000013
</code></pre></div></div>

<hr />

<p><strong>Accounts info:</strong></p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Accounts:
   ID          cash    cash_on_hold    position_val      prev_nav           nav    net_position     VWAP             profit    total_profit    num_trades
----  ------------  --------------  --------------  ------------  ------------  --------------  -------  -----------------  --------------  ------------
   0  -4.51044e+07     3.11089e+07     1.64866e+07   2.49115e+06   2.49115e+06         -375119  39.9751        1.49115e+06     1.49115e+06            74
   1  -3.8919e+07      3.27787e+07     1.07237e+07   4.58351e+06   4.58351e+06          -98798  72.2711        3.58351e+06     3.58351e+06            78
   2  -1.92421e+07     3.55094e+06     9.2696e+06   -6.42158e+06  -6.42158e+06          257489  64.8229       -7.42158e+06    -7.42158e+06            23
   3  -4.46985e+07     4.0254e+07      7.79141e+06   3.34692e+06   3.34692e+06          216428  39.1265  -676658               2.34692e+06            79
</code></pre></div></div>

<hr />

<p>1) <strong>total_sys_profit</strong> (total profit of all agents at each step) should be
equal to 0 (zero-sum game).</p>

<p>2) <strong>total_sys_nav</strong> (total net asset value of all agents at each step) is the total
sum of beginning NAV of all traders(agents).</p>

<p>Note: Small random rounding errors are present.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>total_sys_profit = -9E-21; total_sys_nav = 3999999.999999999999999999991
</code></pre></div></div>

<hr />

<p><strong>Sample output results</strong> for final training iteration:</p>

<p>1) The episode_reward is zero (zero sum game) for each episode.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
</code></pre></div></div>

<p>2) The mean reward of each policy is shown under <code class="highlighter-rouge">policy_reward_mean</code>.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.
.
.
Result for PPO_continuousDoubleAuction-v0_0:
  custom_metrics: {}
  date: 2019-09-30_21-16-20
  done: true
  episode_len_mean: 1001.0
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 4
  episodes_total: 38
  experiment_id: 56cbdad4389343eca5cfd49eadeb3554
  hostname: Duality0.local
  info:
    grad_time_ms: 15007.219
    learner:
      policy_0:
        cur_kl_coeff: 0.0003906250058207661
        cur_lr: 4.999999873689376e-05
        entropy: 10.819798469543457
        entropy_coeff: 0.0
        kl: 8.689265087014064e-06
        model: {}
        policy_loss: 153.9163055419922
        total_loss: 843138688.0
        vf_explained_var: 0.0
        vf_loss: 843138496.0
    num_steps_sampled: 40000
    num_steps_trained: 40000
    opt_peak_throughput: 266.538
    opt_samples: 4000.0
    sample_peak_throughput: 80.462
    sample_time_ms: 49713.208
    update_time_ms: 176.14
  iterations_since_restore: 10
  node_ip: 192.168.1.12
  num_healthy_workers: 2
  off_policy_estimator: {}
  pid: 10220
  policy_reward_mean:
    policy_0: 12414.421052631578
    policy_1: -301.39473684210526
    policy_2: -952.1578947368421
    policy_3: -11160.868421052632
  sampler_perf:
    mean_env_wait_ms: 18.1753569144153
    mean_inference_ms: 4.126144958830859
    mean_processing_ms: 1.5262831265657335
  time_since_restore: 649.1416146755219
  time_this_iter_s: 61.54709506034851
  time_total_s: 649.1416146755219
  timestamp: 1569849380
  timesteps_since_restore: 40000
  timesteps_this_iter: 4000
  timesteps_total: 40000
  training_iteration: 10
  trial_id: ea67f638

2019-09-30 21:16:20,507	WARNING util.py:145 -- The `process_trial` operation took 0.4397752285003662 seconds to complete, which may be a performance bottleneck.
2019-09-30 21:16:21,407	WARNING util.py:145 -- The `experiment_checkpoint` operation took 0.899777889251709 seconds to complete, which may be a performance bottleneck.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/4 CPUs, 0/0 GPUs
Memory usage on this node: 3.3/4.3 GB
Result logdir: /Users/hadron0/ray_results/PPO
Number of trials: 1 ({'TERMINATED': 1})
TERMINATED trials:
 - PPO_continuousDoubleAuction-v0_0:	TERMINATED, [3 CPUs, 0 GPUs], [pid=10220], 649 s, 10 iter, 40000 ts, 0 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/4 CPUs, 0/0 GPUs
Memory usage on this node: 3.3/4.3 GB
Result logdir: /Users/hadron0/ray_results/PPO
Number of trials: 1 ({'TERMINATED': 1})
TERMINATED trials:
 - PPO_continuousDoubleAuction-v0_0:	TERMINATED, [3 CPUs, 0 GPUs], [pid=10220], 649 s, 10 iter, 40000 ts, 0 rew
</code></pre></div></div>

<hr />

<p><br /></p>


<ul class="taxonomy__index">
  
  
    <li>
      <a href="#2020">
        <strong>2020</strong> <span class="taxonomy__count">5</span>
      </a>
    </li>
  
    <li>
      <a href="#2019">
        <strong>2019</strong> <span class="taxonomy__count">24</span>
      </a>
    </li>
  
</ul>



  <section id="2020" class="taxonomy__section">
    <h2 class="archive__subtitle">2020</h2>
    <div class="entries-list">
      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/conv_output/" rel="permalink">Output dimension from convolution layer
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  21 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">How to calculate dimension of output from a convolution layer?

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/colab/" rel="permalink">Changing G drive directory in Colab
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  2 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Changing Google drive directory in Colab.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/linear_regression_bayesian/" rel="permalink">Linear regression (Bayesian)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  26 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Notes on the probability for linear regression (Bayesian)

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/RNN_BPTT_2/" rel="permalink">RNN backprop thru time(BPTT part 2) <script type="math/tex">\frac{\delta h_{t}} {\delta h_{t-1}}</script>
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  22 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Notes on the math for RNN back propagation through time(BPTT), part 2. The 1st
derivative of  with respect to .

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/RNN_BPTT/" rel="permalink">RNN backprop thru time(BPTT)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  34 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Notes on the math for RNN back propagation through time(BPTT).

</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>

  <section id="2019" class="taxonomy__section">
    <h2 class="archive__subtitle">2019</h2>
    <div class="entries-list">
      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/pandas_df_rm_row_with_same_col_val/" rel="permalink">Filter rows with same column values in Pandas dataframe
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  10 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Filter rows with same column values in a Pandas dataframe.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/custom_sagemaker_RL_container/" rel="permalink">Custom Sagemaker reinforcement learning container
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  61 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Building &amp; testing custom Sagemaker RL container.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/sagemaker_RL_custom_env/" rel="permalink">Reinforcement learning custom environment in Sagemaker with Ray (RLlib)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  49 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Demo setup for simple (reinforcement learning) custom environment in Sagemaker.
This example uses Proximal Policy Optimization with Ray (RLlib).

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/DPTH/" rel="permalink">Django + Postgres + Travis CI + Heroku CD
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  69 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Basic workflow of testing a Django &amp; Postgres web app with Travis
(continuous integration) &amp; deployment to Heroku (continuous deployment).

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/DPDTH/" rel="permalink">Django + Postgres + Docker + Travis CI + Heroku CD
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  114 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Basic workflow of testing a dockerized Django &amp; Postgres web app with Travis
(continuous integration) &amp; deployment to Heroku (continuous deployment).

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/docker_travis/" rel="permalink">Dockerized Postgres connection with Django web app in Travis CI
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  17 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Introducing a delay to allow proper connection between dockerized Postgres &amp;
Django web app in Travis CI.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/RLlib_rand_policy/" rel="permalink">Random policy in RLlib
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  18 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Creating &amp; seeding a random policy class in RLlib.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/MARL_CDA_env/" rel="permalink">Custom MARL (multi-agent reinforcement learning) CDA (continuous double auction) environment
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  205 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">A custom MARL (multi-agent reinforcement learning) environment where multiple
agents trade against one another in a CDA (continuous double auction).

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/tf_graph/" rel="permalink">Tensorflow graphs in Tensorboard
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  12 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post demonstrate how setup &amp; access Tensorflow graphs.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/bash_script/" rel="permalink">.bash_profile for Mac
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  13 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post demonstrates how to create customized functions to bundle commands in
a .bash_profile file on Mac.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/RND/" rel="permalink">RND (Random Network Distillation) with Proximal Policy Optimization (PPO) Tensorflow
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  83 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the Random Network Distillation (RND)
with Proximal Policy Optimization (PPO) algorithm.
(continuous version)

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/DPPO_dist_tf/" rel="permalink">DPPO distributed tensorflow
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  61 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the Distributed Proximal Policy
Optimization (Distributed PPO or DPPO) algorithm.
(Distributed continuous version)

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/A3C_dist_tf/" rel="permalink">A3C distributed tensorflow
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  26 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the A3C
(Asynchronous Advantage Actor Critic) algorithm
(Distributed discrete version).

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/A3C_cont_thread_nStep/" rel="permalink">A3C multi-threaded continuous version with N step targets
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  33 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the A3C
(Asynchronous Advantage Actor Critic) algorithm.
(multi-threaded continuous version)

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/A3C_disc_thread_nStep/" rel="permalink">A3C multi-threaded discrete version with N step targets
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  66 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the A3C
(Asynchronous Advantage Actor Critic) algorithm (discrete).
(multi-threaded discrete version)

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/tf_accumulate_grad/" rel="permalink">Accumulate gradients with Tensorflow
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  17 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post demonstrates how to accumulate gradients with Tensorflow.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/dist_tf/" rel="permalink">Distributed Tensorflow
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  76 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post demonstrates a simple usage example of distributed Tensorflow with
Python multiprocessing package.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/n_step_targets/" rel="permalink">N-step targets
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  72 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the N-step Q-values estimation
algorithm.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/py_mpp/" rel="permalink">Python’s multiprocessing package
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  32 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post demonstrates how to use the Python’s multiprocessing package to
achieve parallel data generation.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/np_array_manipulation/" rel="permalink">Numpy array manipulation
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  32 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post provides a simple usage examples for common Numpy array manipulation.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/Duel_DDQN_with_PER/" rel="permalink">Dueling DDQN with PER
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  46 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the Dueling Double Deep Q Network with Priority Experience Replay (Duel DDQN with PER) algorithm.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/Duel_DDQN/" rel="permalink">Dueling DDQN
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  23 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the Dueling Double Deep Q Network
(Dueling DDQN) algorithm.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/DDQN/" rel="permalink">DDQN
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  27 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the Double Deep Q Network (DDQN)
algorithm.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/DQN/" rel="permalink">DQN
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  22 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the Deep Q Network (DQN) algorithm.

</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>


  </div>
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>

      </div>
    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
          <li><a href="https://github.com/ChuaCheowHuan" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 Chua Cheow Huan. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.7.1/js/all.js" integrity="sha384-eVEQC9zshBn0rFj4+TU78eNA19HMNigMviK/PU/FFjLXqa/GKPgX58rvt5Z8PLs7" crossorigin="anonymous"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    
  <script>
    var disqus_config = function () {
      this.page.url = "https://chuacheowhuan.github.io/MARL_CDA_env/";  // Replace PAGE_URL with your page's canonical URL variable
      this.page.identifier = "/MARL_CDA_env"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://https-chuacheowhuan-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>




<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://https-chuacheowhuan-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  


  </body>
</html>
