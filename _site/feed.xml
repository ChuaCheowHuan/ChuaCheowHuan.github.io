<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://chuacheowhuan.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://chuacheowhuan.github.io/" rel="alternate" type="text/html" /><updated>2019-09-04T14:30:39+08:00</updated><id>https://chuacheowhuan.github.io/feed.xml</id><title type="html">Every little gist</title><subtitle></subtitle><author><name>Chua Cheow Huan</name></author><entry><title type="html">Django + Postgres + Travis CI + Heroku CD</title><link href="https://chuacheowhuan.github.io/DPTH/" rel="alternate" type="text/html" title="Django + Postgres + Travis CI + Heroku CD" /><published>2019-09-02T00:00:00+08:00</published><updated>2019-09-02T00:00:00+08:00</updated><id>https://chuacheowhuan.github.io/DPTH</id><content type="html" xml:base="https://chuacheowhuan.github.io/DPTH/">&lt;p&gt;Basic workflow of testing a Django &amp;amp; Postgres web app with Travis
(continuous integration) &amp;amp; deployment to Heroku (continuous deployment).&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Prerequisite:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This post assumes that the reader has accounts with Github, Travis &amp;amp; Heroku &amp;amp;
already has the accounts configured. For example, linking Travis with Github,
setting up Postgres server in Heroku &amp;amp; setting OS environment variables in
Travis &amp;amp; Heroku websites.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Code on my &lt;a href=&quot;https://github.com/ChuaCheowHuan/web_app_DPTH&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;See &lt;a href=&quot;https://chuacheowhuan.github.io/DPDTH&quot;&gt;here&lt;/a&gt; for a Dockerized
version.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Which copy of Postgres to use during the different stages in the workflow?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;During development, the local Postgres database server is used. When testing in
Travis, we’ll used Travis’s copy of Postgres &amp;amp; when deploying, we’ll have to
use Heroku’s copy.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;makemigrations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Always run &lt;code class=&quot;highlighter-rouge&quot;&gt;python manage.py makemigrations&lt;/code&gt; before deployment to Heroku
or in our case, before pushing to Github.&lt;/p&gt;

&lt;p&gt;The actual &lt;code class=&quot;highlighter-rouge&quot;&gt;python manage.py migrate&lt;/code&gt; for the Postgres server addon from
Heroku will be run by the deploy section in the &lt;code class=&quot;highlighter-rouge&quot;&gt;.travis.yml&lt;/code&gt; file.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Listing files &amp;amp; directories in a tree:&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd web_app_DPTH

$ tree -a -I &quot;CS50_web_dev|staticfiles|static|templates|LICENSE|README.md|__init__.py|settings_DPTH_.py|urls.py|wsgi.py|db.sqlite3|airline4_tests_.py|apps.py|migrations|views.py|models.py|flights.csv|manage.py|wait-for-it.sh|admin.py|.git|.travis_DPTH_.yml|Dockerfile|docker-compose.yml&quot;  

.
├── .travis.yml
├── Procfile
├── airline
│   └── settings.py
├── flights
│   └── tests.py
└── requirements.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As shown in the tree above, the 5 files that matter in the workflow:&lt;/p&gt;

&lt;p&gt;1) tests.py&lt;/p&gt;

&lt;p&gt;2) settings.py&lt;/p&gt;

&lt;p&gt;3) requirements.txt&lt;/p&gt;

&lt;p&gt;4) .travis.yml&lt;/p&gt;

&lt;p&gt;5) Procfile&lt;/p&gt;

&lt;p&gt;We will look at the contents of each of the 5 files in the sections below.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;tests.py&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is the test file that Travis will use for testing the app.
You write whatever test you want for Travis to run with.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from django.db.models import Max
from django.test import Client, TestCase

from .models import Airport, Flight, Passenger

# Create your tests here.
class FlightsTestCase(TestCase):

    def setUp(self):

        # Create airports.
        a1 = Airport.objects.create(code=&quot;AAA&quot;, city=&quot;City A&quot;)
        a2 = Airport.objects.create(code=&quot;BBB&quot;, city=&quot;City B&quot;)

        # Create flights.
        Flight.objects.create(origin=a1, destination=a2, duration=100)
        Flight.objects.create(origin=a1, destination=a1, duration=200)
        Flight.objects.create(origin=a2, destination=a1, duration=300)

    # 1
    def test_departures_count(self):
        a = Airport.objects.get(code=&quot;AAA&quot;)
        self.assertEqual(a.departures.count(), 2)

    # 2
    def test_arrivals_count(self):
        a = Airport.objects.get(code=&quot;AAA&quot;)
        self.assertEqual(a.arrivals.count(), 2)

    # 3
    def test_valid_flight(self):
        a1 = Airport.objects.get(code=&quot;AAA&quot;)
        a2 = Airport.objects.get(code=&quot;BBB&quot;)
        f = Flight.objects.get(origin=a1, destination=a2)
        self.assertTrue(f.is_valid_flight())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;settings.py&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Under the database section, the database credentials, as OS environment
variables, has to be made available to Travis &amp;amp; Heroku. They can be set in
their respective websites.&lt;/p&gt;

&lt;p&gt;Add and/or edit the following to the &lt;code class=&quot;highlighter-rouge&quot;&gt;settings.py&lt;/code&gt; file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import django_heroku
import dj_database_url
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',

    'whitenoise.middleware.WhiteNoiseMiddleware',  # new

    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.environ['DATABASE_NAME'],
        'USER': os.environ['DATABASE_USER'],
        'PASSWORD': os.environ['DATABASE_PASSWORD'],
        'HOST': os.environ['DATABASE_HOST'],
        'PORT': os.environ['DATABASE_PORT'],
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;STATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;django_heroku.settings(locals())

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;requirements.txt&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This file lets Travis know what packages are needed for the app.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;django&amp;gt;=2.0.11
psycopg2
psycopg2-binary
dj-database-url==0.5.0
gunicorn
whitenoise
django-heroku
pytz
sqlparse
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;.travis.yml&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This file contains instructions for Travis &amp;amp; is needed when Travis starts
running. &lt;code class=&quot;highlighter-rouge&quot;&gt;$HEROKU_API_KEY&lt;/code&gt; can be generated from the Heroku website &amp;amp;
stored as an OS environment variable in the Travis website.
The test is done with the &lt;strong&gt;Travis’s copy&lt;/strong&gt; of Postgres.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;language: python
python:
    - 3.6
services:
    - postgresql
install:
    - pip install -r requirements.txt
script:
    - python manage.py test
deploy:
    provider: heroku
    api_key: $HEROKU_API_KEY
    app: webapp-dpth
    run: python manage.py migrate
    on: master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Procfile&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This file is for Heroku. It tells Heroku to deploy the web app using Gunicorn
as the production server.&lt;/p&gt;

&lt;p&gt;Note that &lt;code class=&quot;highlighter-rouge&quot;&gt;airline&lt;/code&gt; is the Django project name.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;web: gunicorn airline.wsgi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;The deployed web app&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;With the above files in place, push to Github &amp;amp; Travis will start testing.
After all tests passed, deployment starts. If there isn’t any failures, the
web app will be running on:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://webapp-dpth.herokuapp.com&quot;&gt;https://webapp-dpth.herokuapp.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This &lt;a href=&quot;https://webapp-dpth.herokuapp.com/admin&quot;&gt;link&lt;/a&gt; brings you to the admin
page. It is using the &lt;strong&gt;Heroku’s copy&lt;/strong&gt; of Postgres.&lt;/p&gt;

&lt;p&gt;This &lt;a href=&quot;https://travis-ci.com/ChuaCheowHuan/web_app_DPTH/builds/125456399&quot;&gt;link&lt;/a&gt;
brings you to my built log in Travis.com which shows how a successful
test/deploy built looks like.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Web security:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Please note that web security has not been throughly consider in this basic
workflow describe above. &lt;strong&gt;Do NOT&lt;/strong&gt; simply use the above workflow for
production.&lt;/p&gt;

&lt;p&gt;For example the &lt;code class=&quot;highlighter-rouge&quot;&gt;SECRET_KEY&lt;/code&gt; in the &lt;code class=&quot;highlighter-rouge&quot;&gt;settings.py&lt;/code&gt; isn’t dealt with at all
and web security is really beyond the scope of this post.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Huan</name></author><summary type="html">Basic workflow of testing a Django &amp;amp; Postgres web app with Travis (continuous integration) &amp;amp; deployment to Heroku (continuous deployment).</summary></entry><entry><title type="html">Django + Postgres + Docker + Travis CI + Heroku CD</title><link href="https://chuacheowhuan.github.io/DPDTH/" rel="alternate" type="text/html" title="Django + Postgres + Docker + Travis CI + Heroku CD" /><published>2019-09-02T00:00:00+08:00</published><updated>2019-09-02T00:00:00+08:00</updated><id>https://chuacheowhuan.github.io/DPDTH</id><content type="html" xml:base="https://chuacheowhuan.github.io/DPDTH/">&lt;p&gt;Basic workflow of testing a dockerized Django &amp;amp; Postgres web app with Travis
(continuous integration) &amp;amp; deployment to Heroku (continuous deployment).&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Prerequisite:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1) This post assumes that the reader has accounts with Github, Travis &amp;amp; Heroku
&amp;amp; already has the accounts configured. For example, linking Travis with Github,
adding a Postgres server in Heroku &amp;amp; setting OS environment variables in
Travis &amp;amp; Heroku websites.&lt;/p&gt;

&lt;p&gt;2) Basic working knowledge of Django &amp;amp; Docker.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Code on my &lt;a href=&quot;https://github.com/ChuaCheowHuan/web_app_DPDTH&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Which copy of Postgres to use during the different stages in the workflow?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;During development, we won’t be using a local copy of Postgres database
server. The Docker’s copy of Postgres is used.&lt;/p&gt;

&lt;p&gt;When testing in Travis, we don’t have to ask Travis for a copy of Postgres, we
won’t be using Travis’s copy, we’ll be using the Docker’s copy.&lt;/p&gt;

&lt;p&gt;During deployment, we have to use Heroku’s copy.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;makemigrations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Always run &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose web run python manage.py makemigrations&lt;/code&gt; before
deployment to Heroku or in our case, before pushing to Github.&lt;/p&gt;

&lt;p&gt;The actual &lt;code class=&quot;highlighter-rouge&quot;&gt;python manage.py migrate&lt;/code&gt; for the Postgres server addon from
Heroku will be run in the &lt;code class=&quot;highlighter-rouge&quot;&gt;Procfile&lt;/code&gt; file.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Listing files &amp;amp; directories in a tree:&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd web_app_DPDTH

$ tree -a -I &quot;CS50_web_dev|staticfiles|static|templates|LICENSE|README.md|__init__.py|settings_DPTH_.py|urls.py|wsgi.py|db.sqlite3|airline4_tests_.py|apps.py|migrations|views.py|models.py|flights.csv|manage.py|wait-for-it.sh|admin.py|.git|.travis_DPTH_.yml|__pycache__&quot;

.
├── .travis.yml
├── .travis_DPDTH_.yml
├── .travis_old.yml
├── Dockerfile
├── Procfile
├── airline
│   └── settings.py
├── docker-compose.yml
├── docker_push.sh
├── flights
│   └── tests.py
├── heroku-container-release.sh
└── requirements.txt

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As shown in the tree above, the 9 files that matter in the workflow:&lt;/p&gt;

&lt;p&gt;1) tests.py&lt;/p&gt;

&lt;p&gt;2) settings.py&lt;/p&gt;

&lt;p&gt;3) requirements.txt&lt;/p&gt;

&lt;p&gt;4) Dockerfile&lt;/p&gt;

&lt;p&gt;5) docker-compose.yml&lt;/p&gt;

&lt;p&gt;6) .travis.yml&lt;/p&gt;

&lt;p&gt;7) docker_push.sh&lt;/p&gt;

&lt;p&gt;8) heroku-container-release.sh&lt;/p&gt;

&lt;p&gt;9) Procfile&lt;/p&gt;

&lt;p&gt;We will look at the contents of each of the 9 files in the sections below.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;tests.py&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is the test file that Travis will use for testing the app.
You write whatever test you want for Travis to run with.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from django.db.models import Max
from django.test import Client, TestCase

from .models import Airport, Flight, Passenger

# Create your tests here.
class FlightsTestCase(TestCase):

    def setUp(self):

        # Create airports.
        a1 = Airport.objects.create(code=&quot;AAA&quot;, city=&quot;City A&quot;)
        a2 = Airport.objects.create(code=&quot;BBB&quot;, city=&quot;City B&quot;)

        # Create flights.
        Flight.objects.create(origin=a1, destination=a2, duration=100)
        Flight.objects.create(origin=a1, destination=a1, duration=200)
        Flight.objects.create(origin=a2, destination=a1, duration=300)

    # 1
    def test_departures_count(self):
        a = Airport.objects.get(code=&quot;AAA&quot;)
        self.assertEqual(a.departures.count(), 2)

    # 2
    def test_arrivals_count(self):
        a = Airport.objects.get(code=&quot;AAA&quot;)
        self.assertEqual(a.arrivals.count(), 2)

    # 3
    def test_valid_flight(self):
        a1 = Airport.objects.get(code=&quot;AAA&quot;)
        a2 = Airport.objects.get(code=&quot;BBB&quot;)
        f = Flight.objects.get(origin=a1, destination=a2)
        self.assertTrue(f.is_valid_flight())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;settings.py&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Under the database section, the &lt;code class=&quot;highlighter-rouge&quot;&gt;DATABASES['default']&lt;/code&gt; sets the default
database so the default database is the one connected by the OS environment
variable &lt;code class=&quot;highlighter-rouge&quot;&gt;DATABASE_URL&lt;/code&gt;, however if this is unavailable, we’ll use the one
defined with &lt;code class=&quot;highlighter-rouge&quot;&gt;'HOST': 'db'&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This setup allows us to use &lt;code class=&quot;highlighter-rouge&quot;&gt;'HOST': 'db'&lt;/code&gt; which is the Docker’s copy of
postgres during development phase &amp;amp; also during tesing phase with Travis
while using the Heroku’s copy during deployment which is provided by
connecting to the &lt;code class=&quot;highlighter-rouge&quot;&gt;DATABASE_URL&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;DATABASE_URL&lt;/code&gt;, as an OS environment variable which is generated by
Heroku after a Database is added to the web app in the Heroku website.&lt;/p&gt;

&lt;p&gt;Add and/or edit the following to the &lt;code class=&quot;highlighter-rouge&quot;&gt;settings.py&lt;/code&gt; file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import django_heroku
import dj_database_url
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',

    'whitenoise.middleware.WhiteNoiseMiddleware',  # new

    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'postgres',
        'USER': 'postgres',
        'PASSWORD': 'postgres',
        'HOST': 'db', # Docker's copy of postgres
        'PORT': 5432,
        #'PORT': 5433,
    }
}

DATABASE_URL = os.environ.get('DATABASE_URL')
db_from_env = dj_database_url.config(default=DATABASE_URL, conn_max_age=500, ssl_require=True)
DATABASES['default'].update(db_from_env)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;STATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;django_heroku.settings(locals())

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;requirements.txt&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This file lets Docker &amp;amp; Travis know what packages are needed for the app.
This is needed in &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; &amp;amp; &lt;code class=&quot;highlighter-rouge&quot;&gt;.travis.yml&lt;/code&gt; files.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;django&amp;gt;=2.0.11
psycopg2
psycopg2-binary
dj-database-url==0.5.0
gunicorn
whitenoise
django-heroku
pytz
sqlparse
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Dockerfile&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This contains the instructions for building a Docker image.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;CMD gunicorn airline.wsgi:application --bind 0.0.0.0:$PORT&lt;/code&gt; tells
Docker to use gunicorn as the web server.
See &lt;a href=&quot;https://devcenter.heroku.com/articles/container-registry-and-runtime#testing-an-image-locally&quot;&gt;here&lt;/a&gt;
for details.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM python:3

WORKDIR /usr/src/app

ADD requirements.txt /usr/src/app

RUN pip install -r requirements.txt

ADD . /usr/src/app

# collect static files
RUN python manage.py collectstatic --noinput

CMD gunicorn airline.wsgi:application --bind 0.0.0.0:$PORT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;docker-compose.yml&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This contains the instructions on how to run a Docker containers which is an
instance of a Docker image.&lt;/p&gt;

&lt;p&gt;Notice the &lt;code class=&quot;highlighter-rouge&quot;&gt;sleep&lt;/code&gt; delay introduced in the 2 &lt;code class=&quot;highlighter-rouge&quot;&gt;command:&lt;/code&gt; sections.
See &lt;a href=&quot;https://chuacheowhuan.github.io/docker_travis/&quot;&gt;here&lt;/a&gt; for details.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;version: '3'

services:
    db:
        image: postgres
    migration:
        build: .
        command: bash -c 'while !&amp;lt;/dev/tcp/db/5432; do sleep 1; done; python3 manage.py migrate'
        volumes:
            - .:/usr/src/app
        depends_on:
            - db
    web:
        build: .
#        container_name: webapp-dpdth
        image: webapp-dpdth
        command: bash -c 'while !&amp;lt;/dev/tcp/db/5432; do sleep 1; done; python3 manage.py runserver 0.0.0.0:8000'
        volumes:
            - .:/usr/src/app
        ports:
            - &quot;8000:8000&quot;
        depends_on:
            - db
            - migration

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;.travis.yml&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This file contains instructions for Travis. Notice that we’re not using the
Postgres from Travis because we’re using Postgres from Docker directly.
The &lt;code class=&quot;highlighter-rouge&quot;&gt;postgresql&lt;/code&gt; is therefore commented out under the &lt;code class=&quot;highlighter-rouge&quot;&gt;services:&lt;/code&gt;
section.&lt;/p&gt;

&lt;p&gt;Under &lt;code class=&quot;highlighter-rouge&quot;&gt;script:&lt;/code&gt;, we ask Travis to run the test using Docker with
the &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;Under &lt;code class=&quot;highlighter-rouge&quot;&gt;deploy:&lt;/code&gt;, we execute a &lt;code class=&quot;highlighter-rouge&quot;&gt;docker_push.sh&lt;/code&gt; script, more details in
the sections below.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;skip_cleanup: true&lt;/code&gt; tells Travis not to remove any files that it
deems unnecessary after deployment. Travis does not have permission to do that
on Heroku anyway.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;language: python
python:
    - 3.6
services:
    - docker
#    - postgresql
install:
    - pip install -r requirements.txt
script:
    - docker-compose run web python manage.py test
deploy:
    provider: script
    script: bash docker_push.sh
    skip_cleanup: true
    on:
        branch: master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Workflow for after testing with Travis to deployment to Heroku&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The main workflow after testing to deployment is as such:&lt;/p&gt;

&lt;p&gt;tag image -&amp;gt; push image to registry -&amp;gt; release image&lt;/p&gt;

&lt;p&gt;We’ll see how to do that in the following script files:&lt;/p&gt;

&lt;p&gt;1) docker_push.sh&lt;/p&gt;

&lt;p&gt;2) heroku-container-release.sh&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;docker_push.sh&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This file does several things listed as follows:&lt;/p&gt;

&lt;p&gt;1) Login to the Heroku’s image registry.&lt;/p&gt;

&lt;p&gt;2) &lt;code class=&quot;highlighter-rouge&quot;&gt;tag&lt;/code&gt; the source image &lt;code class=&quot;highlighter-rouge&quot;&gt;webapp-dpdth:latest&lt;/code&gt; to the target
image &lt;code class=&quot;highlighter-rouge&quot;&gt;registry.heroku.com/webapp-dpdth/web&lt;/code&gt;.
Replace &lt;code class=&quot;highlighter-rouge&quot;&gt;webapp-dpdth&lt;/code&gt; with your app name on Heroku.&lt;/p&gt;

&lt;p&gt;3) Push the target image to Heroku’s registry if the branch tested on Travis
is a master branch &amp;amp; that it’s not a PR.&lt;/p&gt;

&lt;p&gt;4) Change ownership &amp;amp; permission of files to allow Travis to execute
the &lt;code class=&quot;highlighter-rouge&quot;&gt;heroku-container-release.sh&lt;/code&gt; script.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;docker login &lt;span class=&quot;nt&quot;&gt;--username&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HEROKU_DOCKER_USERNAME&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--password&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HEROKU_AUTH_TOKEN&lt;/span&gt; registry.heroku.com
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;docker tag webapp-dpdth:latest registry.heroku.com/webapp-dpdth/web
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$TRAVIS_BRANCH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;master&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$TRAVIS_PULL_REQUEST&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;false&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;docker push registry.heroku.com/webapp-dpdth/web&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fi

&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;chmod&lt;/span&gt; +x heroku-container-release.sh
&lt;span class=&quot;nb&quot;&gt;sudo chown&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$USER&lt;/span&gt;:docker ~/.docker
&lt;span class=&quot;nb&quot;&gt;sudo chown&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$USER&lt;/span&gt;:docker ~/.docker/config.json
&lt;span class=&quot;nb&quot;&gt;sudo chmod &lt;/span&gt;g+rw ~/.docker/config.json

./heroku-container-release.sh

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;heroku-container-release.sh&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This file is for releasing a Docker image via Heroku’s API.
Replace &lt;code class=&quot;highlighter-rouge&quot;&gt;webapp-dpdth&lt;/code&gt; with your app name on Heroku.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;imageId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;docker inspect registry.heroku.com/webapp-dpdth/web &lt;span class=&quot;nt&quot;&gt;--format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={{&lt;/span&gt;.Id&lt;span class=&quot;o&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'{&quot;updates&quot;:[{&quot;type&quot;:&quot;web&quot;,&quot;docker_image&quot;:&quot;'&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$imageId&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&quot;}]}'&lt;/span&gt;
curl &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-X&lt;/span&gt; PATCH https://api.heroku.com/apps/webapp-dpdth/formation &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$payload&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Content-Type: application/json&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Accept: application/vnd.heroku+json; version=3.docker-releases&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: Bearer &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HEROKU_AUTH_TOKEN&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;See &lt;a href=&quot;https://devcenter.heroku.com/articles/container-registry-and-runtime#releasing-an-image&quot;&gt;here&lt;/a&gt;
for details.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Procfile&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This file is for Heroku. The command in the &lt;code class=&quot;highlighter-rouge&quot;&gt;release:&lt;/code&gt; section will run
after a Docker image is released. It will run the &lt;code class=&quot;highlighter-rouge&quot;&gt;migrate&lt;/code&gt; command
with &lt;code class=&quot;highlighter-rouge&quot;&gt;--noinput&lt;/code&gt; option. Without running &lt;code class=&quot;highlighter-rouge&quot;&gt;migrate&lt;/code&gt;, the database on
Heroku may not function correctly.&lt;/p&gt;

&lt;p&gt;It also tells Heroku to deploy the web app using Gunicorn as the production
server.&lt;/p&gt;

&lt;p&gt;Note that &lt;code class=&quot;highlighter-rouge&quot;&gt;airline&lt;/code&gt; is the Django project name. It’s not the web app name
in the Django project &amp;amp; is also not the web app name in Heroku.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;release: python manage.py migrate --noinput
web: gunicorn airline.wsgi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;The deployed web app&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;With the above files in place, push to Github &amp;amp; Travis will start testing.
After all tests passed, deployment starts. If there isn’t any failures,
the web app will be running on:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://webapp-dpdth.herokuapp.com&quot;&gt;https://webapp-dpdth.herokuapp.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This &lt;a href=&quot;https://webapp-dpdth.herokuapp.com/admin&quot;&gt;link&lt;/a&gt; brings you to the admin
page. It is using the &lt;strong&gt;Heroku’s copy&lt;/strong&gt; of Postgres.&lt;/p&gt;

&lt;p&gt;This &lt;a href=&quot;https://travis-ci.com/ChuaCheowHuan/web_app_DPDTH/builds/125458792&quot;&gt;link&lt;/a&gt; brings you to my built log in Travis.com which shows how a successful
test/deploy built looks like.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Web security:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Please note that web security has not been throughly consider in this basic
workflow describe above. &lt;strong&gt;Do NOT&lt;/strong&gt; simply use the above workflow for
production.&lt;/p&gt;

&lt;p&gt;For example the &lt;code class=&quot;highlighter-rouge&quot;&gt;SECRET_KEY&lt;/code&gt; in the &lt;code class=&quot;highlighter-rouge&quot;&gt;settings.py&lt;/code&gt; isn’t dealt with at all
and web security is really beyond the scope of this post.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Huan</name></author><summary type="html">Basic workflow of testing a dockerized Django &amp;amp; Postgres web app with Travis (continuous integration) &amp;amp; deployment to Heroku (continuous deployment).</summary></entry><entry><title type="html">Dockerized Postgres connection with Django web app in Travis CI</title><link href="https://chuacheowhuan.github.io/docker_travis/" rel="alternate" type="text/html" title="Dockerized Postgres connection with Django web app in Travis CI" /><published>2019-08-29T00:00:00+08:00</published><updated>2019-08-29T00:00:00+08:00</updated><id>https://chuacheowhuan.github.io/docker_travis</id><content type="html" xml:base="https://chuacheowhuan.github.io/docker_travis/">&lt;p&gt;Introducing a delay to allow proper connection between dockerized Postgres &amp;amp;
Django web app in Travis CI.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Code on my &lt;a href=&quot;https://github.com/ChuaCheowHuan/web_app&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;If you see the following error in the Travis’s job log while attempting to test
dockerized Django apps with Travis, it means that the postgres docker container
has started but not yet ready to accept connections.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;psycopg2.OperationalError: could not connect to server: Connection refused
539	Is the server running on host &quot;db&quot; (172.18.0.2) and accepting
540	TCP/IP connections on port 5432?

.
.
.

django.db.utils.OperationalError: could not connect to server: Connection
refused 587	Is the server running on host &quot;db&quot; (172.18.0.2) and accepting
588	TCP/IP connections on port 5432?

The command &quot;docker-compose run web python manage.py test&quot; exited with 1.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A solution for this issue is to introduce a delay until connection is ready
before executing the test.&lt;/p&gt;

&lt;p&gt;The delay has to be implemented in the &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; file before
migration &amp;amp; running of Django’s server shown below:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;command: bash -c 'while !&amp;lt;/dev/tcp/db/5432; do sleep 1; done; python3 manage.py migrate'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;command: bash -c 'while !&amp;lt;/dev/tcp/db/5432; do sleep 1; done; python3 manage.py runserver 0.0.0.0:8000'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Config files:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;These are the relevant config files used in a Django project with the delay
introduced in the &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; file. The actual command to run the
test is in the &lt;code class=&quot;highlighter-rouge&quot;&gt;.travis.yml&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;The database configuration in &lt;code class=&quot;highlighter-rouge&quot;&gt;settings.py&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'postgres',
        'USER': 'postgres',
        'HOST': 'db',
        'PORT': 5432,
        #'PORT': 5433,
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM python:3
WORKDIR /usr/src/app
ADD requirements.txt /usr/src/app
RUN pip install -r requirements.txt
ADD . /usr/src/app
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; file:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;version: '3'

services:
    db:
        image: postgres
    migration:
        build: .
#        command: python3 manage.py migrate
        command: bash -c 'while !&amp;lt;/dev/tcp/db/5432; do sleep 1; done; python3 manage.py migrate'
        volumes:
            - .:/usr/src/app
        depends_on:
            - db
    web:
        build: .
#        command: python3 manage.py runserver 0.0.0.0:8000
        command: bash -c 'while !&amp;lt;/dev/tcp/db/5432; do sleep 1; done; python3 manage.py runserver 0.0.0.0:8000'
        volumes:
            - .:/usr/src/app
        ports:
            - &quot;8000:8000&quot;
        depends_on:
            - db
            - migration
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;.travis.yml&lt;/code&gt; file:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;language: python
python:
    - 3.6
services:
    - docker
#    - postgres
install:
    - pip install -r requirements.txt
#before_script:
#    - psql -c 'create database testdb;' -U postgres
#    - psql -c 'create database travisci;' -U postgres
script:
#    - docker-compose build
#    - docker-compose run web python manage.py migrate
    - docker-compose run web python manage.py test
#    - python manage.py test
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;After introducing the delay, this is the successful test output in
Travis’s job log.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;.
.
.
.......
528----------------------------------------------------------------------
529Ran 10 tests in 0.126s
530
531OK
532Destroying test database for alias 'default'...
533The command &quot;docker-compose run web python manage.py test&quot; exited with 0.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;references&quot;&gt;References:&lt;/h2&gt;

&lt;p&gt;See this &lt;a href=&quot;https://stackoverflow.com/questions/35069027/docker-wait-for-postgresql-to-be-running&quot;&gt;post&lt;/a&gt; in stackoverflow.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Huan</name></author><summary type="html">Introducing a delay to allow proper connection between dockerized Postgres &amp;amp; Django web app in Travis CI.</summary></entry><entry><title type="html">Random policy in RLlib</title><link href="https://chuacheowhuan.github.io/RLlib_rand_policy/" rel="alternate" type="text/html" title="Random policy in RLlib" /><published>2019-08-29T00:00:00+08:00</published><updated>2019-08-29T00:00:00+08:00</updated><id>https://chuacheowhuan.github.io/RLlib_rand_policy</id><content type="html" xml:base="https://chuacheowhuan.github.io/RLlib_rand_policy/">&lt;p&gt;Creating &amp;amp; seeding a random policy class in RLlib.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Code on my &lt;a href=&quot;https://github.com/ChuaCheowHuan/gym-continuousDoubleAuction/blob/master/gym_continuousDoubleAuction/CDA_env_cont_RLlib.py&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Function:&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def make_RandomPolicy(_seed):

    # a hand-coded policy that acts at random in the env (doesn't learn)
    class RandomPolicy(Policy):
        &quot;&quot;&quot;Hand-coded policy that returns random actions.&quot;&quot;&quot;
        def __init__(self, observation_space, action_space, config):
            self.observation_space = observation_space
            self.action_space = action_space
            self.action_space.seed(_seed)

        def compute_actions(self,
                            obs_batch,
                            state_batches,
                            prev_action_batch=None,
                            prev_reward_batch=None,
                            info_batch=None,
                            episodes=None,
                            **kwargs):
            &quot;&quot;&quot;Compute actions on a batch of observations.&quot;&quot;&quot;
            return [self.action_space.sample() for _ in obs_batch], [], {}

        def learn_on_batch(self, samples):
            &quot;&quot;&quot;No learning.&quot;&quot;&quot;
            #return {}
            pass

        def get_weights(self):
            pass

        def set_weights(self, weights):
            pass

    return RandomPolicy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Usage example:&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Setup PPO with an ensemble of `num_policies` different policies
    policies = {&quot;policy_{}&quot;.format(i): gen_policy(i) for i in range(args.num_policies)} # contains many &quot;policy_graphs&quot; in a policies dictionary

    # override policy with random policy
    policies[&quot;policy_{}&quot;.format(args.num_policies-3)] = (make_RandomPolicy(1), obs_space, act_space, {}) # random policy stored as the last item in policies dictionary
    policies[&quot;policy_{}&quot;.format(args.num_policies-2)] = (make_RandomPolicy(2), obs_space, act_space, {}) # random policy stored as the last item in policies dictionary
    policies[&quot;policy_{}&quot;.format(args.num_policies-1)] = (make_RandomPolicy(3), obs_space, act_space, {}) # random policy stored as the last item in policies dictionary
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Huan</name></author><summary type="html">Creating &amp;amp; seeding a random policy class in RLlib.</summary></entry><entry><title type="html">Custom MARL (multi-agent reinforcement learning) CDA (continuous double auction) environment</title><link href="https://chuacheowhuan.github.io/MARL_CDA_env/" rel="alternate" type="text/html" title="Custom MARL (multi-agent reinforcement learning) CDA (continuous double auction) environment" /><published>2019-08-11T00:00:00+08:00</published><updated>2019-08-11T00:00:00+08:00</updated><id>https://chuacheowhuan.github.io/MARL_CDA_env</id><content type="html" xml:base="https://chuacheowhuan.github.io/MARL_CDA_env/">&lt;p&gt;A custom MARL (multi-agent reinforcement learning) environment where multiple
agents trade against one another in a CDA (continuous double auction).&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Code on my &lt;a href=&quot;https://github.com/ChuaCheowHuan/gym-continuousDoubleAuction&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The environment doesn’t use any external data. Data is generated by self play
of the agents themselves through their interaction with the limit order book.&lt;/p&gt;

&lt;p&gt;At each time step, the environment emits the top k rows of the aggregated
order book as observations to the agents.&lt;/p&gt;

&lt;h1 id=&quot;example&quot;&gt;Example:&lt;/h1&gt;
&lt;p&gt;An example of using RLlib to pit 1 PPO (Proximal Policy Optimization) agent
against 3 random agents using this CDA environment is available in:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CDA_env_disc_RLlib.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To run:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd gym-continuousDoubleAuction/gym_continuousDoubleAuction
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python CDA_env_disc_RLlib.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The figure below from Tensorboard shows the agents’ performance:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/MARL_CDA_env/agent0and1.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;/assets/images/MARL_CDA_env/agent2and3.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;PPO agent is using policy 0 while policies 1 to 3 are used by the random agents.&lt;/p&gt;

&lt;h1 id=&quot;dependencies&quot;&gt;Dependencies:&lt;/h1&gt;
&lt;p&gt;1) Tensorflow&lt;/p&gt;

&lt;p&gt;2) OpenAI’s Gym&lt;/p&gt;

&lt;p&gt;3) Ray &amp;amp; RLlib&lt;/p&gt;

&lt;h1 id=&quot;installation&quot;&gt;Installation:&lt;/h1&gt;
&lt;p&gt;The environment is installable via pip.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd gym-continuousDoubleAuction
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install -e .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;todo&quot;&gt;TODO:&lt;/h1&gt;
&lt;p&gt;1) custom RLlib workflow to include custom RND + PPO policies.&lt;/p&gt;

&lt;p&gt;2) parametric or hybrid action space&lt;/p&gt;

&lt;p&gt;3) more documentation&lt;/p&gt;

&lt;h1 id=&quot;acknowledgements&quot;&gt;Acknowledgements:&lt;/h1&gt;
&lt;p&gt;The orderbook matching engine is adapted from
https://github.com/dyn4mik3/OrderBook&lt;/p&gt;

&lt;h1 id=&quot;disclaimer&quot;&gt;Disclaimer:&lt;/h1&gt;
&lt;p&gt;This repository is only meant for research purposes &amp;amp; is &lt;strong&gt;never&lt;/strong&gt; meant to be
used in any form of trading. Past performance is no guarantee of future results.
If you suffer losses from using this repository, you are the sole person
responsible for the losses. The author will &lt;strong&gt;NOT&lt;/strong&gt; be held responsible in any
way.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Huan</name></author><summary type="html">A custom MARL (multi-agent reinforcement learning) environment where multiple agents trade against one another in a CDA (continuous double auction).</summary></entry><entry><title type="html">Tensorflow graphs in Tensorboard</title><link href="https://chuacheowhuan.github.io/tf_graph/" rel="alternate" type="text/html" title="Tensorflow graphs in Tensorboard" /><published>2019-07-04T00:00:00+08:00</published><updated>2019-07-04T00:00:00+08:00</updated><id>https://chuacheowhuan.github.io/tf_graph</id><content type="html" xml:base="https://chuacheowhuan.github.io/tf_graph/">&lt;p&gt;This post demonstrate how setup &amp;amp; access Tensorflow graphs.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;In order to access Tensorflow graphs, you need to use &lt;a href=&quot;https://www.tensorflow.org/tensorboard/r2/get_started&quot;&gt;Tensorboard&lt;/a&gt; which comes will Tensorflow
installed.&lt;/p&gt;

&lt;p&gt;The following snippet shows how to setup a &lt;code class=&quot;highlighter-rouge&quot;&gt;FileWriter&lt;/code&gt; with a Tensorflow
graph.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tf.reset_default_graph()
sess = tf.Session()

# Your Tensorflow graph goes here.
# ...

sess.run(tf.global_variables_initializer())

# Declare tf.summary.FileWriter where log is your output directory for
# Tensorboard &amp;amp; add the graph to the writer.
writer = tf.summary.FileWriter('log', sess.graph)

# Run your training loop
# sess.run(...)

writer.close()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Run this command in terminal to start tensorboard:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tensorboard --logdir log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Navigate to &lt;code class=&quot;highlighter-rouge&quot;&gt;http://127.0.0.1:6006&lt;/code&gt; in your browser to access Tensorflow.
Your graph is in the graph tab.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Huan</name></author><summary type="html">This post demonstrate how setup &amp;amp; access Tensorflow graphs.</summary></entry><entry><title type="html">.bash_profile for Mac</title><link href="https://chuacheowhuan.github.io/bash_script/" rel="alternate" type="text/html" title=".bash_profile for Mac" /><published>2019-07-03T00:00:00+08:00</published><updated>2019-07-03T00:00:00+08:00</updated><id>https://chuacheowhuan.github.io/bash_script</id><content type="html" xml:base="https://chuacheowhuan.github.io/bash_script/">&lt;p&gt;This post demonstrates how to create customized functions to bundle commands in
a .bash_profile file on Mac.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Edit .bash_profile for Mac.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Start Terminal&lt;/li&gt;
  &lt;li&gt;Enter “cd ~/” to go to home folder&lt;/li&gt;
  &lt;li&gt;Edit .bash_profile with “open -e .bash_profile” to open in TextEdit.&lt;/li&gt;
  &lt;li&gt;Enter “. .bash_profile” to reload .bash_profile.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;examples&quot;&gt;Examples&lt;/h2&gt;

&lt;p&gt;To bundle common git operations, add the following to .bash_profile file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;function lazy_git() {
    git checkout test_ver
    git add .
    git commit -a -m &quot;$1&quot;
    git checkout master
    git merge test_ver
    git push
    git checkout test_ver
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;hr /&gt;

&lt;p&gt;To bundle common jekyll operations, add the following to .bash_profile file:&lt;/p&gt;

&lt;p&gt;The command &lt;code class=&quot;highlighter-rouge&quot;&gt;serve&lt;/code&gt; runs localhost.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;function lazy_jekyll_serve() {
    cd /Users/tester/gitHubRepo/ChuaCheowHuan.github.io
    pwd
    bundle exec jekyll serve
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The command &lt;code class=&quot;highlighter-rouge&quot;&gt;build&lt;/code&gt; build the site. This command is neccessary for
generating sitemap.xml &amp;amp; robot.txt.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;function lazy_jekyll_build() {
    cd /Users/tester/gitHubRepo/ChuaCheowHuan.github.io
    pwd
    bundle exec jekyll build
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Huan</name></author><summary type="html">This post demonstrates how to create customized functions to bundle commands in a .bash_profile file on Mac.</summary></entry><entry><title type="html">RND (Random Network Distillation) with Proximal Policy Optimization (PPO) Tensorflow</title><link href="https://chuacheowhuan.github.io/RND/" rel="alternate" type="text/html" title="RND (Random Network Distillation) with Proximal Policy Optimization (PPO) Tensorflow" /><published>2019-06-25T00:00:00+08:00</published><updated>2019-06-25T00:00:00+08:00</updated><id>https://chuacheowhuan.github.io/RND</id><content type="html" xml:base="https://chuacheowhuan.github.io/RND/">&lt;p&gt;This post documents my implementation of the Random Network Distillation (RND)
with Proximal Policy Optimization (PPO) algorithm.
(&lt;strong&gt;continuous&lt;/strong&gt; version)&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Random Network Distillation (RND) with Proximal Policy Optimization (PPO)
implentation in Tensorflow. This is a continuous version which solves the
mountain car continuous problem (MountainCarContinuous-v0).
The RND helps learning with curiosity driven exploration.&lt;/p&gt;

&lt;p&gt;The agent starts to converge correctly at around 30 episodes &amp;amp; reached the flag
291 times out of 300 episodes (97% hit rate). It takes 385.09387278556824
seconds to complete 300 episodes on Google’s Colab.&lt;/p&gt;

&lt;p&gt;Edit: A new version which corrects a numerical error(causes nan action) takes
780.2065596580505 seconds for 300 episodes. Both versions have similar results.
The URL for the new version is updated. Added random seeds for numpy &amp;amp; Tensorflow global seed &amp;amp; ops seed achieve better consistency &amp;amp; faster convergence.&lt;/p&gt;

&lt;p&gt;Checkout the &lt;a href=&quot;https://chuacheowhuan.github.io/RND/#charts&quot;&gt;resulting
charts&lt;/a&gt; from the program output.&lt;/p&gt;

&lt;p&gt;Code on my Github:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/ChuaCheowHuan/reinforcement_learning/blob/master/RND_PPO/RND_PPO_cont_ftr_nsn_mtcar_php.py&quot;&gt;Python file&lt;/a&gt;,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/ChuaCheowHuan/reinforcement_learning/blob/master/RND_PPO/RND_PPO_cont_ftr_nsn_mtCar_php.ipynb&quot;&gt;Jupyter notebook&lt;/a&gt;
(The Jupyter notebook, which also contain the resulting charts at the end, can be run directly on Google’s Colab.)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;notations--equations&quot;&gt;Notations &amp;amp; equations&lt;/h2&gt;

&lt;p&gt;fixed feature from target network =
&lt;script type=&quot;math/tex&quot;&gt;{ f (s_{t+1}) }&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;predicted feature from predictor network =
&lt;script type=&quot;math/tex&quot;&gt;{ f ^\prime  (s_{t+1}) }&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;intrinsic reward =
&lt;script type=&quot;math/tex&quot;&gt;r_{i}&lt;/script&gt; =
||
&lt;script type=&quot;math/tex&quot;&gt;{ f ^\prime  (s_{t+1}) }&lt;/script&gt; -
&lt;script type=&quot;math/tex&quot;&gt;{ f (s_{t+1}) }&lt;/script&gt;
||
&lt;script type=&quot;math/tex&quot;&gt;{}{^2}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;For notations &amp;amp; equations regarding PPO, refer to this
&lt;a href=&quot;https://chuacheowhuan.github.io/DPPO_dist_tf/&quot;&gt;post&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;key-implementation-details&quot;&gt;Key implementation details:&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Preprocessing, state featurization:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Prior to training, the states are featurized with the RBF kernel.&lt;/p&gt;

&lt;p&gt;(states are also featurized during every training batch.)&lt;/p&gt;

&lt;p&gt;Refer to scikit-learn.org documentation: &lt;a href=&quot;https://scikit-learn.org/stable/modules/kernel_approximation.html#rbf-kernel-approx&quot;&gt;5.7.2. Radial Basis Function Kernel&lt;/a&gt; for more information on RBF kernel.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;if state_ftr == True:
&quot;&quot;&quot;
The following code for state featurization is adapted &amp;amp; modified from dennybritz's repository located at:
https://github.com/dennybritz/reinforcement-learning/blob/master/PolicyGradient/Continuous%20MountainCar%20Actor%20Critic%20Solution.ipynb
&quot;&quot;&quot;
    # Feature Preprocessing: Normalize to zero mean and unit variance
    # We use a few samples from the observation space to do this
    states = np.array([env.observation_space.sample() for x in range(sample_size)]) # pre-trained, states preprocessing
    scaler = sklearn.preprocessing.StandardScaler()
    scaler.fit(states) # Compute the mean and std to be used for later scaling.

    # convert states to a featurizes representation.
    # We use RBF kernels with different variances to cover different parts of the space
    featurizer = sklearn.pipeline.FeatureUnion([ # Concatenates results of multiple transformer objects.
            (&quot;rbf1&quot;, RBFSampler(gamma=5.0, n_components=n_comp)),
            (&quot;rbf2&quot;, RBFSampler(gamma=2.0, n_components=n_comp)),
            (&quot;rbf3&quot;, RBFSampler(gamma=1.0, n_components=n_comp)),
            (&quot;rbf4&quot;, RBFSampler(gamma=0.5, n_components=n_comp))
            ])
    featurizer.fit(
        scaler.transform(states)) # Perform standardization by centering and scaling

# state featurization of state(s) only,
# not used on s_ for RND's target &amp;amp; predictor networks
def featurize_state(state):
    scaled = scaler.transform([state]) # Perform standardization by centering and scaling
    featurized = featurizer.transform(scaled) # Transform X separately by each transformer, concatenate results.
    return featurized[0]

def featurize_batch_state(batch_states):
    fs_list = []
    for s in batch_states:
        fs = featurize_state(s)
        fs_list.append(fs)
    return fs_list
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Preprocessing, next state normalization for RND:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Variance is computed for the next states &lt;code class=&quot;highlighter-rouge&quot;&gt;buffer_s_&lt;/code&gt; using
the &lt;code class=&quot;highlighter-rouge&quot;&gt;RunningStats&lt;/code&gt; class. During every training batch, the next states are
normalize and clipped.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def state_next_normalize(sample_size, running_stats_s_):

  buffer_s_ = []
  s = env.reset()
  for i in range(sample_size):
    a = env.action_space.sample()
    s_, r, done, _ = env.step(a)
    buffer_s_.append(s_)

  running_stats_s_.update(np.array(buffer_s_))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;if state_next_normal == True:
  state_next_normalize(sample_size, running_stats_s_)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;tensorboard-graphs&quot;&gt;Tensorboard graphs:&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Big picture:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;There are two main modules, the PPO and the RND.&lt;/p&gt;

&lt;p&gt;Current state, &lt;code class=&quot;highlighter-rouge&quot;&gt;state&lt;/code&gt; is passed into PPO.&lt;/p&gt;

&lt;p&gt;Next state, &lt;code class=&quot;highlighter-rouge&quot;&gt;state_&lt;/code&gt; is passed into RND.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/RND_PPO_tf_graph_img/main.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;PPO module:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;PPO module contains the actor network &amp;amp; the critic network.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/RND_PPO_tf_graph_img/PPO.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;PPO’s actor:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;At every iteration, an action is sampled from policy network &lt;code class=&quot;highlighter-rouge&quot;&gt;pi&lt;/code&gt;.
&lt;img src=&quot;/assets/images/RND_PPO_tf_graph_img/PPO_a.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;PPO’s critic:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The critic contains two value function networks. One for extrinsic rewards &amp;amp; one
 for intrinsic rewards. Two sets of TD lambda returns &amp;amp; advantages are also
 computed.&lt;/p&gt;

&lt;p&gt;For extrinsic rewards: &lt;code class=&quot;highlighter-rouge&quot;&gt;tdlamret adv&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;For intrinsic rewards: &lt;code class=&quot;highlighter-rouge&quot;&gt;tdlamret_i adv_i&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The TD lambda returns are used as the PPO’s critics targets in their respective
networks while the advantages are summed &amp;amp; used as the advantage in the actor’s
loss computation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/RND_PPO_tf_graph_img/PPO_c.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;RND module:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;RND module contains the target network &amp;amp; the predictor network.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/RND_PPO_tf_graph_img/RND.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;RND target network:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The target network is a fixed network, meaning that it’s never trained.
It’s weights are randomized once during initialization. The target network is
used to encode next states &lt;code class=&quot;highlighter-rouge&quot;&gt;state_&lt;/code&gt;. It’s output are encoded next states.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/RND_PPO_tf_graph_img/RND_t.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;RND predictor network:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;predictor_loss&lt;/code&gt; is the intrinsic reward. It is the difference between
the predictor network’s output with the target network’s output. The predictor
network is trying to guess the target network’s encoded output.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/RND_PPO_tf_graph_img/RND_p.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;key-to-note&quot;&gt;Key to note:&lt;/h2&gt;

&lt;p&gt;All networks used in this program are linear.&lt;/p&gt;

&lt;p&gt;The actor module is basically similar to this DPPO &lt;a href=&quot;https://github.com/ChuaCheowHuan/reinforcement_learning/blob/master/DPPO/DPPO_cont_GAE_dist_GPU.ipynb&quot;&gt;code&lt;/a&gt; documented in this &lt;a href=&quot;https://chuacheowhuan.github.io/DPPO_dist_tf/&quot;&gt;post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The difference is in the critic module. This implementation has two value
functions in the critic module rather than one.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;predictor_loss&lt;/code&gt; is the intrinsic reward.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/RND_PPO_tf_graph_img/key.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;problems-encountered&quot;&gt;Problems encountered:&lt;/h2&gt;

&lt;p&gt;The actor’s network occasionally returns ‘'’nan’’’ for action. This happens randomly, most likely caused by exploding gradients.
Not initializing or randomly initializing actor’s weights results in nan when outputting action.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a name=&quot;charts&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;program-output&quot;&gt;Program output:&lt;/h2&gt;

&lt;p&gt;hit_counter 291 0.97&lt;/p&gt;

&lt;p&gt;Number of steps per episode:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/RND_PPO_tf_graph_img/output/steps.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Reward per episode:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/RND_PPO_tf_graph_img/output/reward.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Moving average reward per episode:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/RND_PPO_tf_graph_img/output/mv_avg.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;— 385.09387278556824 seconds —&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;references&quot;&gt;References:&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1810.12894.pdf&quot;&gt;Exploration by Random Network Distillation&lt;/a&gt;
(Yuri Burda, Harrison Edwards, Amos Storkey, Oleg Klimov, 2018)&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Huan</name></author><summary type="html">This post documents my implementation of the Random Network Distillation (RND) with Proximal Policy Optimization (PPO) algorithm. (continuous version)</summary></entry><entry><title type="html">DPPO distributed tensorflow</title><link href="https://chuacheowhuan.github.io/DPPO_dist_tf/" rel="alternate" type="text/html" title="DPPO distributed tensorflow" /><published>2019-06-25T00:00:00+08:00</published><updated>2019-06-25T00:00:00+08:00</updated><id>https://chuacheowhuan.github.io/DPPO_dist_tf</id><content type="html" xml:base="https://chuacheowhuan.github.io/DPPO_dist_tf/">&lt;p&gt;This post documents my implementation of the Distributed Proximal Policy
Optimization (Distributed PPO or DPPO) algorithm.
(&lt;strong&gt;Distributed&lt;/strong&gt; continuous version)&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Distributed Proximal Policy Optimization (Distributed PPO or DPPO) continuous
version implementation with distributed Tensorflow and Python’s multiprocessing
package. This implementation uses normalized running rewards with GAE. The code
is tested with Gym’s continuous action space environment, Pendulum-v0 on Colab.&lt;/p&gt;

&lt;p&gt;Code on my &lt;a href=&quot;https://github.com/ChuaCheowHuan/reinforcement_learning/blob/master/DPPO/DPPO_cont_GAE_dist_GPU.ipynb&quot;&gt;Github&lt;/a&gt;:&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;notations&quot;&gt;Notations:&lt;/h2&gt;

&lt;p&gt;current policy =
&lt;script type=&quot;math/tex&quot;&gt;{\pi}_{\theta}
(a_{t}
  {\mid} s_{t})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;old policy =
&lt;script type=&quot;math/tex&quot;&gt;{\pi}_{\theta_{old}}
(a_{t}
  {\mid} s_{t})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;epsilon =
&lt;script type=&quot;math/tex&quot;&gt;{\epsilon}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Advantage function = A&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;equations&quot;&gt;Equations:&lt;/h2&gt;

&lt;p&gt;Truncated version of generalized advantage estimation (GAE) =&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;A_{t}&lt;/script&gt;
=
&lt;script type=&quot;math/tex&quot;&gt;{\delta}_{t}
+
({\gamma}
{\lambda})
{\delta}_{t}
+
...
+
({\gamma}
{\lambda})
^{T-t+1}
{\delta}_{T-1}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;where
&lt;script type=&quot;math/tex&quot;&gt;{\delta}_{t}&lt;/script&gt; =
&lt;script type=&quot;math/tex&quot;&gt;{r}_{t} +
{\gamma}
V(s_{t+1}) -
V(s_{t})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;when &lt;script type=&quot;math/tex&quot;&gt;{\lambda}&lt;/script&gt; = 1,&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;A_{t}&lt;/script&gt; =
&lt;script type=&quot;math/tex&quot;&gt;-V(s_{t}) +
r_{t} +
{\gamma}r_{t+1} +
... +
{\gamma}^{T-t+1}
r_{T-1} +
{\gamma}^{T-t}
V(s_{T})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Probability ratio =&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;R_{t}({\theta})&lt;/script&gt; = &lt;script type=&quot;math/tex&quot;&gt;{\dfrac{ {\pi}_{\theta} (a_{t} {\mid} s_{t}) } { {\pi}_{\theta_{old}} (a_{t} {\mid} s_{t}) } }&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Clipped Surrogate Objective function =&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;L^{CLIP}
({\theta})&lt;/script&gt;
=
&lt;script type=&quot;math/tex&quot;&gt;\mathop{\mathbb{E_{t}}}
\lbrack
min(
  R_{t}({\theta})
  A_{t}
  ,
  clip
  (
    R_{t}({\theta}),
    1+{\epsilon},
    1-{\epsilon}
    )
    A_{t}
  )
\rbrack&lt;/script&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;key-implementation-details&quot;&gt;Key implementation details:&lt;/h2&gt;

&lt;p&gt;The following class is adapted from OpenAI’s baseline:
This class is used for the normalization of rewards in this program before GAE
computation.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class RunningStats(object):
    def __init__(self, epsilon=1e-4, shape=()):
        self.mean = np.zeros(shape, 'float64')
        self.var = np.ones(shape, 'float64')
        self.std = np.ones(shape, 'float64')
        self.count = epsilon

    def update(self, x):
        batch_mean = np.mean(x, axis=0)
        batch_var = np.var(x, axis=0)
        batch_count = x.shape[0]
        self.update_from_moments(batch_mean, batch_var, batch_count)

    def update_from_moments(self, batch_mean, batch_var, batch_count):
        delta = batch_mean - self.mean
        new_mean = self.mean + delta * batch_count / (self.count + batch_count)
        m_a = self.var * self.count
        m_b = batch_var * batch_count
        M2 = m_a + m_b + np.square(delta) * self.count * batch_count / (self.count + batch_count)
        new_var = M2 / (self.count + batch_count)

        self.mean = new_mean
        self.var = new_var
        self.std = np.maximum(np.sqrt(self.var), 1e-6)
        self.count = batch_count + self.count
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This function in the &lt;code class=&quot;highlighter-rouge&quot;&gt;PPO&lt;/code&gt; class is adapted from OpenAI’s Baseline,
returns TD lamda return &amp;amp; advantage&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    def add_vtarg_and_adv(self, R, done, V, v_s_, gamma, lam):
        # Compute target value using TD(lambda) estimator, and advantage with GAE(lambda)
        # last element is only used for last vtarg, but we already zeroed it if last new = 1
        done = np.append(done, 0)
        V_plus = np.append(V, v_s_)
        T = len(R)
        adv = gaelam = np.empty(T, 'float32')
        lastgaelam = 0
        for t in reversed(range(T)):
            nonterminal = 1-done[t+1]        
            delta = R[t] + gamma * V_plus[t+1] * nonterminal - V_plus[t]
            gaelam[t] = lastgaelam = delta + gamma * lam * nonterminal * lastgaelam   
        #print(&quot;adv=&quot;, adv.shape)
        #print(&quot;V=&quot;, V.shape)
        #print(&quot;V_plus=&quot;, V_plus.shape)
        tdlamret = np.vstack(adv) + V
        #print(&quot;tdlamret=&quot;, tdlamret.shape)
        return tdlamret, adv # tdlamret is critic_target or Qs      
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following code segment from the &lt;code class=&quot;highlighter-rouge&quot;&gt;PPO&lt;/code&gt; class defines the Clipped Surrogate
Objective function:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;with tf.variable_scope('surrogate'):
                    ratio = self.pi.prob(self.act) / self.oldpi.prob(self.act)
                    surr = ratio * self.adv
                    self.aloss = -tf.reduce_mean(tf.minimum(surr, tf.clip_by_value(ratio, 1.-epsilon, 1.+epsilon)*self.adv))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following code segment from the &lt;code class=&quot;highlighter-rouge&quot;&gt;work()&lt;/code&gt; function in the worker class
normalized the running rewards for each worker:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;self.running_stats_r.update(np.array(buffer_r))
                    buffer_r = np.clip( (np.array(buffer_r) - self.running_stats_r.mean) / self.running_stats_r.std, -stats_CLIP, stats_CLIP )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following code segment from the &lt;code class=&quot;highlighter-rouge&quot;&gt;work()&lt;/code&gt; function in the worker class computes
 the TD lamda return &amp;amp; advantage:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tdlamret, adv = self.ppo.add_vtarg_and_adv(np.vstack(buffer_r), np.vstack(buffer_done), np.vstack(buffer_V), v_s_, GAMMA, lamda)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following update function in the &lt;code class=&quot;highlighter-rouge&quot;&gt;PPO&lt;/code&gt; class does the training &amp;amp; the
updating of global &amp;amp; local parameters (Note the at the beginning of training,
  probability ratio = 1):&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def update(self, s, a, r, adv):    
    self.sess.run(self.update_oldpi_op)

    for _ in range(A_EPOCH): # train actor
        self.sess.run(self.atrain_op, {self.state: s, self.act: a, self.adv: adv})
        # update actor
        self.sess.run([self.push_actor_pi_params,
                       self.pull_actor_pi_params],
                      {self.state: s, self.act: a, self.adv: adv})
    for _ in range(C_EPOCH): # train critic
        # update critic
        self.sess.run(self.ctrain_op, {self.state: s, self.discounted_r: r})
        self.sess.run([self.push_critic_params,
                       self.pull_critic_params],
                      {self.state: s, self.discounted_r: r})   
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;The distributed Tensorflow &amp;amp; multiprocessing code sections are very similar to
the ones describe in the following posts:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://chuacheowhuan.github.io/A3C_dist_tf/&quot;&gt;A3C distributed tensorflow&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://chuacheowhuan.github.io/dist_tf/&quot;&gt;Distributed Tensorflow&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;references&quot;&gt;References:&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.06347.pdf&quot;&gt;Proximal Policy Optimization Algorithms&lt;/a&gt;
(Schulman, Wolski, Dhariwal, Radford, Klimov, 2017)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1707.02286.pdf&quot;&gt;Emergence of Locomotion Behaviours in Rich Environments&lt;/a&gt;
(Nicolas Heess, Dhruva TB, Srinivasan Sriram, Jay Lemmon, Josh Merel, Greg Wayne, et al., 2017)&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Huan</name></author><summary type="html">This post documents my implementation of the Distributed Proximal Policy Optimization (Distributed PPO or DPPO) algorithm. (Distributed continuous version)</summary></entry><entry><title type="html">A3C distributed tensorflow</title><link href="https://chuacheowhuan.github.io/A3C_dist_tf/" rel="alternate" type="text/html" title="A3C distributed tensorflow" /><published>2019-06-25T00:00:00+08:00</published><updated>2019-06-25T00:00:00+08:00</updated><id>https://chuacheowhuan.github.io/A3C_dist_tf</id><content type="html" xml:base="https://chuacheowhuan.github.io/A3C_dist_tf/">&lt;p&gt;This post documents my implementation of the A3C
(Asynchronous Advantage Actor Critic) algorithm
(&lt;strong&gt;Distributed&lt;/strong&gt; discrete version).&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;A3C (Asynchronous Advantage Actor Critic) implementation with &lt;strong&gt;distributed
Tensorflow&lt;/strong&gt; &amp;amp; &lt;strong&gt;Python multiprocessing package&lt;/strong&gt;. This is a &lt;strong&gt;discrete&lt;/strong&gt;
version with N-step targets (use maximum terms possible). The code is tested
with Gym’s discrete action space environment, CartPole-v0 on Colab.&lt;/p&gt;

&lt;p&gt;Code on my &lt;a href=&quot;https://github.com/ChuaCheowHuan/reinforcement_learning/blob/master/A3C/A3C_disc_max_dist.ipynb&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The majority of the code is very similar to the &lt;a href=&quot;https://chuacheowhuan.github.io/A3C_disc_thread_nStep/&quot;&gt;discrete&lt;/a&gt; version with the
exceptions highlighted in the implementation details section:&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;key-implementation-details&quot;&gt;Key implementation details:&lt;/h2&gt;

&lt;p&gt;Updating the global episode counter &amp;amp; adding the episodic return to a
tf.FIFOqueue at the end of the work() function.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SESS.run(GLOBAL_EP.assign_add(1.0))
qe = GLOBAL_RUNNING_R.enqueue(ep_r)
SESS.run(qe)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The distributed Tensorflow part is very similar to a simple example described in
this &lt;a href=&quot;https://chuacheowhuan.github.io/dist_tf/&quot;&gt;post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Pin the global variables under the parameter server in both the parameter_server() &amp;amp; worker(worker_n) function:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;with tf.device(&quot;/job:ps/task:0&quot;):
    GLOBAL_AC = ACNet(net_scope, sess, globalAC=None) # only need its params
    GLOBAL_EP = tf.Variable(0.0, name='GLOBAL_EP') # num of global episodes   
    # a queue of ep_r
    GLOBAL_RUNNING_R = tf.FIFOQueue(max_global_episodes, tf.float32, shared_name=&quot;GLOBAL_RUNNING_R&quot;)        
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the parameter_server() function, check the size of the tf.FIFOqueue every 1 sec.
If it’s full, dequeue the items in a list. the list will be used for display.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;while True:
    time.sleep(1.0)
    #print(&quot;ps 1 GLOBAL_EP: &quot;, sess.run(GLOBAL_EP))
    #print(&quot;ps 1 GLOBAL_RUNNING_R.size(): &quot;, sess.run(GLOBAL_RUNNING_R.size()))  
    if sess.run(GLOBAL_RUNNING_R.size()) &amp;gt;= max_global_episodes: # GLOBAL_EP starts from 0, hence +1 to max_global_episodes          
        time.sleep(5.0)
        #print(&quot;ps 2 GLOBAL_RUNNING_R.size(): &quot;, sess.run(GLOBAL_RUNNING_R.size()))  
        GLOBAL_RUNNING_R_list = []
        for j in range(sess.run(GLOBAL_RUNNING_R.size())):
            ep_r = sess.run(GLOBAL_RUNNING_R.dequeue())
            GLOBAL_RUNNING_R_list.append(ep_r) # for display
        break
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Huan</name></author><summary type="html">This post documents my implementation of the A3C (Asynchronous Advantage Actor Critic) algorithm (Distributed discrete version).</summary></entry></feed>