<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.15.2 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">



<link rel="stylesheet" href="/assets/css/main.css">
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async>
</script>



  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>A3C multi-threaded discrete version with N step targets -</title>
<meta name="description" content="pending update…">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="">
<meta property="og:title" content="A3C multi-threaded discrete version with N step targets">
<meta property="og:url" content="http://localhost:4000/A3C_disc_thread_nStep/">


  <meta property="og:description" content="pending update…">



  <meta property="og:image" content="http://localhost:4000/assets/images/bio-photo.jpg">





  <meta property="article:published_time" content="2019-06-13T00:00:00+08:00">





  

  


<link rel="canonical" href="http://localhost:4000/A3C_disc_thread_nStep/">





  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Organization",
      "url": "http://localhost:4000",
      "logo": "http://localhost:4000/assets/images/bio-photo.jpg"
    }
  </script>



  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "Chua Cheow Huan",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--posts">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/"></a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/" >Home</a>
            </li><li class="masthead__menu-item">
              <a href="/blog/index.html" >Blog</a>
            </li><li class="masthead__menu-item">
              <a href="/about/index.html" >About</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name"></h3>
    
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>

  <div class="archive">
    
      <h1 id="page-title" class="page__title">A3C multi-threaded discrete version with N step targets</h1>
    
    <p>pending update…</p>

<p>This post demonstrates how to implement the A3C (Asynchronous Advantage Actor Critic) algorithm with Tensorflow. This is a multi-threaded discrete version.</p>

<p>Environment from OpenAI’s gym: CartPole-v0 (Discrete)</p>

<p><a href="https://">Full code</a>: A3C (discrete) multi-threaded version with N-step targets(missing terms are treated as 0)</p>

<p><a href="https://">Full code</a>: A3C (discrete) multi-threaded version with N-step
targets(use maximum terms possible)</p>

<hr />

<p><strong>Notations:</strong></p>

<p>Actor network = <script type="math/tex">{\pi}_{\theta}</script></p>

<p>Actor network parameter = <script type="math/tex">{\theta}</script></p>

<p>Critic network = <script type="math/tex">V_{\phi}</script></p>

<p>Critic network parameter = <script type="math/tex">\phi</script></p>

<p>Advantage function = A</p>

<p>Number of trajectories = m</p>

<hr />

<p><strong>Equations:</strong></p>

<p>Actor component: log<script type="math/tex">{\pi}_{\theta}</script> <script type="math/tex">(a_{t} {\mid} s_{t})</script></p>

<p>Critic component = Advantage function = A = <script type="math/tex">Q(s_{t}, a_{t})</script> - <script type="math/tex">V_{\phi}(s_{t})</script></p>

<p>Q values with N-step truncated estimate :</p>

<p><script type="math/tex">Q^{\pi}(s_{t}, a_{t})</script> = E(<script type="math/tex">r_{t}</script> + <script type="math/tex">\gamma</script> <script type="math/tex">r_{t+1}</script> + <script type="math/tex">\gamma^{2}</script> <script type="math/tex">r_{t+2}</script> + … + <script type="math/tex">\gamma^{n}</script> V(<script type="math/tex">s_{t+n}</script>))</p>

<p>Check this <a href="https://chuacheowhuan.github.io/n_step_targets/">post</a> for more information on N-step truncated estimate.</p>

<p>Policy gradient estimator</p>

<p>= <script type="math/tex">\nabla_\theta J(\theta)</script></p>

<p>= <script type="math/tex">{\dfrac{1}{m}}</script> <script type="math/tex">{\sum\limits_{i=1}^{m}}</script> <script type="math/tex">{\sum\limits_{t=0}^{T}}</script> <script type="math/tex">\nabla_\theta</script> log<script type="math/tex">{\pi}_{\theta}</script> <script type="math/tex">(a_{t} {\mid} s_{t})</script> <script type="math/tex">Q(s_{t}, a_{t})</script> - <script type="math/tex">V_{\phi}(s_{t})</script></p>

<p>= <script type="math/tex">{\dfrac{1}{m}}</script> <script type="math/tex">{\sum\limits_{i=1}^{m}}</script> <script type="math/tex">{\sum\limits_{t=0}^{T}}</script> <script type="math/tex">\nabla_\theta</script> log<script type="math/tex">{\pi}_{\theta}</script> <script type="math/tex">(a_{t} {\mid} s_{t})</script> A</p>

<hr />

<p><strong>Implementation details:</strong></p>

<p>The ACNet class defines the models (Tensorflow graphs) and contains both the actor and the critic networks.</p>

<p>The Worker class contains the work function that does the main bulk of the computation.</p>

<p>A copy of ACNet is declared globally &amp; the parameters are shared by the threaded workers. Each worker also have it’s own local copy of ACNet.</p>

<p>Workers are instantiated &amp; threaded in the main program.</p>

<p><strong>ACNet class:</strong></p>

<p>Loss function for the actor network for the discrete environment:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>with tf.name_scope('actor_loss'):
    log_prob = tf.reduce_sum(tf.log(self.action_prob + 1e-5) * tf.one_hot(self.a, num_actions, dtype=tf.float32), axis=1, keep_dims=True)
    actor_component = log_prob * tf.stop_gradient(self.baselined_returns)
    # entropy for exploration
    entropy = -tf.reduce_sum(self.action_prob * tf.log(self.action_prob + 1e-5), axis=1, keep_dims=True)  # encourage exploration
    self.actor_loss = tf.reduce_mean( -(ENTROPY_BETA * entropy + actor_component) )                                        
</code></pre></div></div>
<p>Loss function for the critic network for the discrete environment:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TD_err = tf.subtract(self.critic_target, self.V, name='TD_err')
      .
      .
      .
with tf.name_scope('critic_loss'):
    self.critic_loss = tf.reduce_mean(tf.square(TD_err))
</code></pre></div></div>

<p>The following function in the ACNet class creates the actor and critic’s neural networks:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def _create_net(self, scope):
    w_init = tf.glorot_uniform_initializer()
    with tf.variable_scope('actor'):
        hidden = tf.layers.dense(self.s, actor_hidden, tf.nn.relu6, kernel_initializer=w_init, name='hidden')
        action_prob = tf.layers.dense(hidden, num_actions, tf.nn.softmax, kernel_initializer=w_init, name='action_prob')        
    with tf.variable_scope('critic'):
        hidden = tf.layers.dense(self.s, critic_hidden, tf.nn.relu6, kernel_initializer=w_init, name='hidden')
        V = tf.layers.dense(hidden, 1, kernel_initializer=w_init, name='V')         
    actor_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/actor')
    critic_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/critic')       
    return action_prob, V, actor_params, critic_params
</code></pre></div></div>

<p><strong>Worker class:</strong></p>

<p>Discounted rewards are used as critic’s targets:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>critic_target = self.discount_rewards(buffer_r, GAMMA, V_s)
</code></pre></div></div>

<p>N-step targets are used in the computation of the Advantage function(baselined_returns):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Advantage function
baselined_returns = n_step_targets - baseline
</code></pre></div></div>

<p>2 versions of N-step targets could be used:</p>

<p>Version 1) missing terms are treated as 0.</p>

<p>Version 2) use maximum terms possible.</p>

<p>Check this <a href="https://chuacheowhuan.github.io/n_step_targets/">post</a> for more information on N-step targets.</p>

<p>The following code segment accumulates gradients &amp; apply them to the local critic network:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>self.AC.accumu_grad_critic(feed_dict) # accumulating gradients for local critic  
self.AC.apply_accumu_grad_critic(feed_dict)
</code></pre></div></div>

<p>The following code segment computes the advantage function(baselined_returns):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>baseline = SESS.run(self.AC.V, {self.AC.s: buffer_s}) # Value function
epr = np.vstack(buffer_r).astype(np.float32)
n_step_targets = self.compute_n_step_targets_missing(epr, baseline, GAMMA, N_step) # Q values
# Advantage function
baselined_returns = n_step_targets - baseline
</code></pre></div></div>

<p>The following code segment accumulates gradients for the local actor network:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>self.AC.accumu_grad_actor(feed_dict) # accumulating gradients for local actor  
</code></pre></div></div>

<p>The following code segment push the parameters from the local networks to the global networks and then pulls the updated global parameters to the local networks:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># update
self.AC.push_global_actor(feed_dict)                
self.AC.push_global_critic(feed_dict)
    .
    .
    .
self.AC.pull_global()
</code></pre></div></div>

<p>The following code segment initialize storage for accumulated local gradients.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>self.AC.init_grad_storage_actor() # initialize storage for accumulated gradients.
self.AC.init_grad_storage_critic()            
</code></pre></div></div>

<p>Check this <a href="https://chuacheowhuan.github.io/tf_accumulate_grad/">post</a> for more information on how to accumulate gradients in Tensorflow.</p>

<p><strong>Main program:</strong></p>

<p>The following code segment creates the workers:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>workers = []
for i in range(num_workers): # Create worker
    i_name = 'W_%i' % i # worker name
    workers.append(Worker(i_name, GLOBAL_AC))
</code></pre></div></div>

<p>The following code segment threads the workers:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>worker_threads = []
for worker in workers:
    job = lambda: worker.work()
    t = threading.Thread(target=job)
    t.start()
    worker_threads.append(t)
COORD.join(worker_threads)
</code></pre></div></div>

<p><strong>References:</strong></p>

<p><a href="https://arxiv.org/pdf/1602.01783.pdf">Asynchronous Methods for Deep Reinforcement Learning
(Mnih, Badia, Mirza, Graves, Harley, Lillicrap, et al., 2016)</a></p>

<p><br /></p>


<ul class="taxonomy__index">
  
  
    <li>
      <a href="#2019">
        <strong>2019</strong> <span class="taxonomy__count">11</span>
      </a>
    </li>
  
</ul>



  <section id="2019" class="taxonomy__section">
    <h2 class="archive__subtitle">2019</h2>
    <div class="entries-list">
      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/A3C_cont_thread_nStep/" rel="permalink">A3C multi-threaded continuous version with N step targets
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  31 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">pending update…

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/A3C_disc_thread_nStep/" rel="permalink">A3C multi-threaded discrete version with N step targets
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  61 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">pending update…

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/tf_accumulate_grad/" rel="permalink">Accumulate gradients with Tensorflow
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  14 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post demonstrates how to accumulate gradients with Tensorflow.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/dist_tf/" rel="permalink">Distributed Tensorflow
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  73 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Distributed Tensorflow with Python multiprocessing package.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/n_step_targets/" rel="permalink">N-step targets
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  68 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">N-step Q-values estimation.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/py_mpp/" rel="permalink">Python’s multiprocessing package
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  30 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Python’s multiprocessing package for parallel data generation.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/np_array_manipulation/" rel="permalink">Numpy array manipulation
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  29 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Simple numpy array manipulation examples.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/Duel_DDQN_with_PER/" rel="permalink">Dueling DDQN with PER
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  41 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">A Dueling Double Deep Q Network with Priority Experience Replay (Duel DDQN with PER) implementation in tensorflow.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/Duel_DDQN/" rel="permalink">Dueling DDQN
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  18 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">A Dueling Double Deep Q Network (Dueling DDQN) implementation in tensorflow with random experience replay.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/DDQN/" rel="permalink">DDQN
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  22 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">A Double Deep Q Network (DDQN) implementation in tensorflow with random experience replay.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/DQN/" rel="permalink">DQN
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  17 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">A Deep Q Network implementation in tensorflow with target network &amp; random experience replay.

</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>


  </div>
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>

      </div>
    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
          <li><a href="https://github.com/ChuaCheowHuan" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2019 Chua Cheow Huan. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.7.1/js/all.js" integrity="sha384-eVEQC9zshBn0rFj4+TU78eNA19HMNigMviK/PU/FFjLXqa/GKPgX58rvt5Z8PLs7" crossorigin="anonymous"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    
  <script>
    var disqus_config = function () {
      this.page.url = "http://localhost:4000/A3C_disc_thread_nStep/";  // Replace PAGE_URL with your page's canonical URL variable
      this.page.identifier = "/A3C_disc_thread_nStep"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://https-chuacheowhuan-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>




<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://https-chuacheowhuan-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  


  </body>
</html>
