<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.15.2 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">



<link rel="stylesheet" href="/assets/css/main.css">
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async>
</script>



  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>PBT for MARL - Every little gist</title>
<meta name="description" content="My attempt to implement a water down version of PBT (Population based training) for MARL (Multi-agent reinforcement learning).">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Every little gist">
<meta property="og:title" content="PBT for MARL">
<meta property="og:url" content="http://localhost:4000/PBT_MARL_watered_down/">


  <meta property="og:description" content="My attempt to implement a water down version of PBT (Population based training) for MARL (Multi-agent reinforcement learning).">



  <meta property="og:image" content="http://localhost:4000/assets/images/bio-photo.jpg">





  <meta property="article:published_time" content="2020-06-12T00:00:00+08:00">





  

  


<link rel="canonical" href="http://localhost:4000/PBT_MARL_watered_down/">





  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Organization",
      "url": "http://localhost:4000",
      "logo": "http://localhost:4000/assets/images/bio-photo.jpg"
    }
  </script>



  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "Chua Cheow Huan",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>



  <meta name="google-site-verification" content="googlec75336ce8806a8d5.html" />





<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Every little gist Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--posts">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">Every little gist</a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/" >Home</a>
            </li><li class="masthead__menu-item">
              <a href="/blog/index.html" >Blog</a>
            </li><li class="masthead__menu-item">
              <a href="/about/index.html" >About</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name"></h3>
    
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>

  <div class="archive">
    
      <h1 id="page-title" class="page__title">PBT for MARL</h1>
    
    <p>My attempt to implement a water down version of PBT (Population based training) for MARL (Multi-agent reinforcement learning).</p>

<p>Code on my <a href="https://github.com/ChuaCheowHuan/PBT_MARL_watered_down">Github</a></p>

<hr />

<h1 id="pbt_marl_watered_down">PBT_MARL_watered_down</h1>

<h1 id="whats-in-this-repo">What’s in this repo?</h1>

<p>My attempt to implement a water down version of PBT (Population based training) for MARL (Multi-agent reinforcement learning) inspired by Algorithm 1 (PBT-MARL) on page 3 of this <a href="https://arxiv.org/pdf/1902.07151.pdf">paper</a>[1].</p>

<h1 id="main-differences-from-the-paper">MAIN differences from the paper:</h1>

<p>(1) A simple 1 VS 1 <a href="https://github.com/ray-project/ray/blob/57544b1ff9f97d4da9f64d25c8ea5a3d8d247ffc/rllib/examples/env/rock_paper_scissors.py">RockPaperScissorsEnv</a> environment (adapted &amp; modified from a toy example from ray) is used instead of the 2 VS 2 <a href="https://git.io/dm_soccer">dm_soccer</a>.</p>

<p>(2) PPO is used instead of SVG0.</p>

<p>(3) No reward shaping.</p>

<p>(4) The evolution eligibility documented in B2 on page 16 in the <a href="https://arxiv.org/pdf/1902.07151.pdf">paper</a>[1] is not implemented.</p>

<p>(5) Probably many more…</p>

<h1 id="what-works">What works?</h1>

<p>(1) Policies weights can be inherited between different agents in the population.</p>

<p>(2) Learning rate &amp; gamma are the only 2 hyperparameters involved for now. Both can be inherited/mutated. Learning rate can be resampled/perturbed while gamma can only be resampled.</p>

<h1 id="simple-walkthru">Simple walkthru:</h1>

<p>Before each training iteration, the driver (in this context, the main process, this is also where the RLlib trainer resides) randomly selects a pair of agents (agt_i, agt_j, where i != j) from a population of agents. This i, j pair will take up the role of player_A &amp; player_B respectively.</p>

<p>The IDs of i,j will be transmitted down to the worker processes. Each worker has 1 or more environments (<a href="https://rllib.readthedocs.io/en/latest/rllib-env.html#vectorized">vectorized</a>) &amp; does it’s own rollout. When an episode is sampled (that’s when a match ends), the <code class="highlighter-rouge">on_episode_end</code> callback will be called. That’s when the ratings of a match are computed &amp; updated to a global storage.</p>

<p>When enough samples are collected, training starts. Training is done using <a href="https://docs.ray.io/en/master/rllib-algorithms.html#decentralized-distributed-proximal-policy-optimization-dd-ppo">RLlib’s DDPPO</a> (a variant of PPO). In DDPPO, learning does not happened in the trainer. Each worker does it’s own learning. However, the trainer is still involved in the weight sync.</p>

<p>When a training iteration completes, <code class="highlighter-rouge">on_train_results</code> callback will be called. That’s where inheritance &amp; mutation happens (if conditions are fulfilled).</p>

<p>All of the above happens during 1 single main training loop of the driver. Rinse &amp; repeat.</p>

<p>Note: Global coordination between different processes is done using <a href="https://docs.ray.io/en/master/advanced.html#detached-actors">detached actors</a> from ray.</p>

<h1 id="example-of-whats-stored-in-the-global-storage">Example of what’s stored in the global storage:</h1>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"""
{'agt_0':
    {'hyperparameters':
        {'lr': [0.0027558, 0.0022046, ...]},
         'gamma': [0.9516804908336309, 0.9516804908336309, ...]
     'opponent': ['NA', 'agt_5', 'agt_5', ...],
     'score': [0, -4.0, -2.0, ...],
     'rating': [0.0, 0.05, 0.05, ...],
     'step': [0]},
 'agt_1': ...
    .
    .
    .
 'agt_n': ...    
}
"""
</code></pre></div></div>

<h1 id="how-to-run-the-contents-in-this-repo">How to run the contents in this repo?</h1>

<p>The easiest way is to run the <code class="highlighter-rouge">PBT_MARL_watered_down.ipynb</code> Jupyter notebook in Colab.</p>

<h1 id="dependencies">Dependencies:</h1>

<p>This is developed &amp; tested on Colab &amp; the following are the only packages that I explicitly <code class="highlighter-rouge">pip install</code>:</p>

<p>ray[rllib]==0.8.5</p>

<p>tensorflow==2.2.0</p>

<h1 id="disclaimer">Disclaimer:</h1>

<p>(1) I’m not affiliated with any of the authors of the <a href="https://arxiv.org/pdf/1902.07151.pdf">paper</a>[1].</p>

<h1 id="references">References:</h1>

<p>[1] <a href="https://arxiv.org/pdf/1902.07151.pdf">EMERGENT COORDINATION THROUGH COMPETITION (Liu et al., 2019)</a></p>

<hr />

<p><br /></p>


<ul class="taxonomy__index">
  
  
    <li>
      <a href="#2020">
        <strong>2020</strong> <span class="taxonomy__count">7</span>
      </a>
    </li>
  
    <li>
      <a href="#2019">
        <strong>2019</strong> <span class="taxonomy__count">24</span>
      </a>
    </li>
  
</ul>



  <section id="2020" class="taxonomy__section">
    <h2 class="archive__subtitle">2020</h2>
    <div class="entries-list">
      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/PBT_MARL_watered_down/" rel="permalink">PBT for MARL
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  47 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">My attempt to implement a water down version of PBT (Population based training) for MARL (Multi-agent reinforcement learning).

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/RLlib_trainer_config/" rel="permalink">RLlib trainer common config
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  232 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Ray (0.8.2) RLlib trainer common config from:

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/conv_output/" rel="permalink">Output dimension from convolution layer
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  21 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">How to calculate dimension of output from a convolution layer?

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/colab/" rel="permalink">Changing G drive directory in Colab
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  2 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Changing Google drive directory in Colab.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/linear_regression_bayesian/" rel="permalink">Linear regression (Bayesian)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  26 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Notes on the probability for linear regression (Bayesian)

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/RNN_BPTT_2/" rel="permalink">RNN backprop thru time(BPTT part 2) <script type="math/tex">\frac{\delta h_{t}} {\delta h_{t-1}}</script>
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  22 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Notes on the math for RNN back propagation through time(BPTT), part 2. The 1st
derivative of  with respect to .

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/RNN_BPTT/" rel="permalink">RNN backprop thru time(BPTT)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  34 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Notes on the math for RNN back propagation through time(BPTT).

</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>

  <section id="2019" class="taxonomy__section">
    <h2 class="archive__subtitle">2019</h2>
    <div class="entries-list">
      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/pandas_df_rm_row_with_same_col_val/" rel="permalink">Filter rows with same column values in Pandas dataframe
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  10 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Filter rows with same column values in a Pandas dataframe.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/custom_sagemaker_RL_container/" rel="permalink">Custom Sagemaker reinforcement learning container
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  61 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Building &amp; testing custom Sagemaker RL container.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/sagemaker_RL_custom_env/" rel="permalink">Reinforcement learning custom environment in Sagemaker with Ray (RLlib)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  49 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Demo setup for simple (reinforcement learning) custom environment in Sagemaker.
This example uses Proximal Policy Optimization with Ray (RLlib).

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/DPTH/" rel="permalink">Django + Postgres + Travis CI + Heroku CD
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  69 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Basic workflow of testing a Django &amp; Postgres web app with Travis
(continuous integration) &amp; deployment to Heroku (continuous deployment).

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/DPDTH/" rel="permalink">Django + Postgres + Docker + Travis CI + Heroku CD
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  114 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Basic workflow of testing a dockerized Django &amp; Postgres web app with Travis
(continuous integration) &amp; deployment to Heroku (continuous deployment).

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/docker_travis/" rel="permalink">Dockerized Postgres connection with Django web app in Travis CI
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  17 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Introducing a delay to allow proper connection between dockerized Postgres &amp;
Django web app in Travis CI.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/RLlib_rand_policy/" rel="permalink">Random policy in RLlib
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  18 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Creating &amp; seeding a random policy class in RLlib.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/MARL_CDA_env/" rel="permalink">Custom MARL (multi-agent reinforcement learning) CDA (continuous double auction) environment
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  220 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">A custom MARL (multi-agent reinforcement learning) environment where multiple
agents trade against one another in a CDA (continuous double auction).

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/tf_graph/" rel="permalink">Tensorflow graphs in Tensorboard
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  12 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post demonstrate how setup &amp; access Tensorflow graphs.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/bash_script/" rel="permalink">.bash_profile for Mac
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  15 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post demonstrates how to create customized functions to bundle commands in
a .bash_profile file on Mac.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/RND/" rel="permalink">RND (Random Network Distillation) with Proximal Policy Optimization (PPO) Tensorflow
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  89 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the Random Network Distillation (RND)
with Proximal Policy Optimization (PPO) algorithm.
(continuous version)

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/DPPO_dist_tf/" rel="permalink">DPPO distributed tensorflow
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  72 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the Distributed Proximal Policy
Optimization (Distributed PPO or DPPO) algorithm.
(Distributed continuous version)

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/A3C_dist_tf/" rel="permalink">A3C distributed tensorflow
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  27 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the A3C
(Asynchronous Advantage Actor Critic) algorithm
(Distributed discrete version).

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/A3C_cont_thread_nStep/" rel="permalink">A3C multi-threaded continuous version with N step targets
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  35 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the A3C
(Asynchronous Advantage Actor Critic) algorithm.
(multi-threaded continuous version)

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/A3C_disc_thread_nStep/" rel="permalink">A3C multi-threaded discrete version with N step targets
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  75 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the A3C
(Asynchronous Advantage Actor Critic) algorithm (discrete).
(multi-threaded discrete version)

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/tf_accumulate_grad/" rel="permalink">Accumulate gradients with Tensorflow
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  17 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post demonstrates how to accumulate gradients with Tensorflow.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/dist_tf/" rel="permalink">Distributed Tensorflow
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  78 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post demonstrates a simple usage example of distributed Tensorflow with
Python multiprocessing package.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/n_step_targets/" rel="permalink">N-step targets
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  79 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the N-step Q-values estimation
algorithm.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/py_mpp/" rel="permalink">Python’s multiprocessing package
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  33 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post demonstrates how to use the Python’s multiprocessing package to
achieve parallel data generation.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/np_array_manipulation/" rel="permalink">Numpy array manipulation
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  33 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post provides a simple usage examples for common Numpy array manipulation.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/Duel_DDQN_with_PER/" rel="permalink">Dueling DDQN with PER
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  53 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the Dueling Double Deep Q Network with Priority Experience Replay (Duel DDQN with PER) algorithm.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/Duel_DDQN/" rel="permalink">Dueling DDQN
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  25 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the Dueling Double Deep Q Network
(Dueling DDQN) algorithm.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/DDQN/" rel="permalink">DDQN
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  31 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the Double Deep Q Network (DDQN)
algorithm.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/DQN/" rel="permalink">DQN
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  26 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This post documents my implementation of the Deep Q Network (DQN) algorithm.

</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>


  </div>
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>

      </div>
    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
          <li><a href="https://github.com/ChuaCheowHuan" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 Chua Cheow Huan. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.7.1/js/all.js" integrity="sha384-eVEQC9zshBn0rFj4+TU78eNA19HMNigMviK/PU/FFjLXqa/GKPgX58rvt5Z8PLs7" crossorigin="anonymous"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    
  <script>
    var disqus_config = function () {
      this.page.url = "http://localhost:4000/PBT_MARL_watered_down/";  // Replace PAGE_URL with your page's canonical URL variable
      this.page.identifier = "/PBT_MARL_watered_down"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://https-chuacheowhuan-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>




<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://https-chuacheowhuan-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  


  </body>
</html>
